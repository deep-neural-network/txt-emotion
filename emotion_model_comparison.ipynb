{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hv4blo-Cgpub"
   },
   "source": [
    "# Comprehensive Emotion Classification Model Comparison\n",
    "\n",
    "**Author:** Sleep Well  \n",
    "**Date:** 2025-08-04  \n",
    "**Purpose:** Compare multiple state-of-the-art deep learning models for text emotion classification\n",
    "\n",
    "This notebook provides a comprehensive comparison of 6 different deep learning models for emotion classification, including both traditional architectures and modern transformer-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C03ozA_mgpuc"
   },
   "source": [
    "## 1. Environment Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PyTorch 2.7.1+cu126 imported successfully!\n",
      "üî• Device: GPU\n",
      "‚úÖ Transformers imported successfully!\n",
      "‚úÖ Datasets imported successfully!\n",
      "‚úÖ Plotly imported successfully!\n",
      "\n",
      "üìä Environment Status:\n",
      "   PyTorch: ‚úÖ\n",
      "   Transformers: ‚úÖ\n",
      "   Datasets: ‚úÖ\n",
      "   Plotly: ‚úÖ\n",
      "\n",
      "üöÄ Environment setup completed!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries (always available)\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import math\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Check for PyTorch availability\n",
    "TORCH_AVAILABLE = False\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    from torch.utils.data import DataLoader, Dataset\n",
    "    from torch.nn.utils.rnn import pad_sequence\n",
    "    TORCH_AVAILABLE = True\n",
    "    print(f\"‚úÖ PyTorch {torch.__version__} imported successfully!\")\n",
    "    print(f\"üî• Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è PyTorch not available: {e}\")\n",
    "    print(\"üìù Will use NumPy-based implementations\")\n",
    "\n",
    "# Check for Transformers availability\n",
    "TRANSFORMERS_AVAILABLE = False\n",
    "try:\n",
    "    from transformers import (\n",
    "        AutoTokenizer, AutoModelForSequenceClassification,\n",
    "        get_linear_schedule_with_warmup\n",
    "    )\n",
    "    TRANSFORMERS_AVAILABLE = True\n",
    "    print(\"‚úÖ Transformers imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Transformers not available: {e}\")\n",
    "    print(\"üìù Will use traditional models only\")\n",
    "\n",
    "# Check for Datasets availability\n",
    "DATASETS_AVAILABLE = False\n",
    "try:\n",
    "    from datasets import load_dataset\n",
    "    DATASETS_AVAILABLE = True\n",
    "    print(\"‚úÖ Datasets imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Datasets not available: {e}\")\n",
    "    print(\"üìù Will use sample data\")\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "PLOTLY_AVAILABLE = False\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    import plotly.express as px\n",
    "    from plotly.subplots import make_subplots\n",
    "    PLOTLY_AVAILABLE = True\n",
    "    print(\"‚úÖ Plotly imported successfully!\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Plotly not available - will use matplotlib\")\n",
    "\n",
    "# Progress tracking\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except ImportError:\n",
    "    # Fallback tqdm\n",
    "    class tqdm:\n",
    "        def __init__(self, iterable, desc=\"\", *args, **kwargs):\n",
    "            self.iterable = iterable\n",
    "            self.desc = desc\n",
    "        def __iter__(self):\n",
    "            for i, item in enumerate(self.iterable):\n",
    "                if i % 10 == 0:\n",
    "                    print(f\"\\r{self.desc}: {i}/{len(self.iterable)}\", end=\"\")\n",
    "                yield item\n",
    "        def set_postfix(self, *args, **kwargs):\n",
    "            pass\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"\\nüìä Environment Status:\")\n",
    "print(f\"   PyTorch: {'‚úÖ' if TORCH_AVAILABLE else '‚ùå'}\")\n",
    "print(f\"   Transformers: {'‚úÖ' if TRANSFORMERS_AVAILABLE else '‚ùå'}\")\n",
    "print(f\"   Datasets: {'‚úÖ' if DATASETS_AVAILABLE else '‚ùå'}\")\n",
    "print(f\"   Plotly: {'‚úÖ' if PLOTLY_AVAILABLE else '‚ùå'}\")\n",
    "print(\"\\nüöÄ Environment setup completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Created directory: models\n",
      "üìÅ Created directory: results\n",
      "üìÅ Created directory: visualizations\n",
      "üìÅ Created directory: logs\n",
      "üìÅ Created directory: checkpoints\n",
      "\n",
      "‚úÖ Project structure initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create necessary directories\n",
    "directories = ['models', 'results', 'visualizations', 'logs', 'checkpoints']\n",
    "\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"üìÅ Created directory: {directory}\")\n",
    "\n",
    "print(\"\\n‚úÖ Project structure initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObHkDLjsgpue"
   },
   "source": [
    "## 2. Configuration and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Configuration initialized:\n",
      "   Device: cuda\n",
      "   Batch size: 16\n",
      "   Max epochs: 3\n",
      "   Emotion labels: ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "# Global configuration\n",
    "@dataclass\n",
    "class GlobalConfig:\n",
    "    # Dataset settings\n",
    "    dataset_name: str = \"dair-ai/emotion\"\n",
    "    num_labels: int = 6\n",
    "    emotion_labels: List[str] = None\n",
    "\n",
    "    # Training settings\n",
    "    batch_size: int = 16\n",
    "    max_epochs: int = 3\n",
    "    learning_rate: float = 2e-5\n",
    "    warmup_steps: int = 500\n",
    "    max_length: int = 128\n",
    "\n",
    "    # Hardware settings\n",
    "    device: str = \"cuda\" if TORCH_AVAILABLE and torch.cuda.is_available() else \"cpu\"\n",
    "    mixed_precision: bool = True\n",
    "\n",
    "    # Evaluation settings\n",
    "    eval_steps: int = 500\n",
    "    save_steps: int = 1000\n",
    "\n",
    "    # Visualization settings\n",
    "    figure_width: int = 1000\n",
    "    figure_height: int = 600\n",
    "    color_palette: str = \"viridis\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.emotion_labels is None:\n",
    "            self.emotion_labels = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "\n",
    "# Initialize global configuration\n",
    "config = GlobalConfig()\n",
    "\n",
    "print(f\"üîß Configuration initialized:\")\n",
    "print(f\"   Device: {config.device}\")\n",
    "print(f\"   Batch size: {config.batch_size}\")\n",
    "print(f\"   Max epochs: {config.max_epochs}\")\n",
    "print(f\"   Emotion labels: {config.emotion_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8yIJkhRgpuf"
   },
   "source": [
    "## 3. Utility Functions and Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Reproducibility set with seed: 42\n",
      "üõ†Ô∏è Utility functions initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "def setup_reproducibility(seed: int = 42):\n",
    "    \"\"\"Set up reproducible training environment\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if TORCH_AVAILABLE:\n",
    "        torch.manual_seed(seed)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(seed)\n",
    "    print(f\"üéØ Reproducibility set with seed: {seed}\")\n",
    "\n",
    "def get_model_size(model):\n",
    "    \"\"\"Calculate model size in parameters\"\"\"\n",
    "    if TORCH_AVAILABLE and hasattr(model, 'parameters'):\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "    else:\n",
    "        return 0  # Fallback for non-PyTorch models\n",
    "\n",
    "def format_time(seconds):\n",
    "    \"\"\"Format time in human readable format\"\"\"\n",
    "    if seconds < 60:\n",
    "        return f\"{seconds:.1f}s\"\n",
    "    elif seconds < 3600:\n",
    "        return f\"{seconds/60:.1f}m\"\n",
    "    else:\n",
    "        return f\"{seconds/3600:.1f}h\"\n",
    "\n",
    "def save_results(results: Dict, filename: str):\n",
    "    \"\"\"Save results to JSON file\"\"\"\n",
    "    filepath = os.path.join('results', filename)\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(results, f, indent=2, default=str)\n",
    "    print(f\"üíæ Results saved to {filepath}\")\n",
    "\n",
    "def load_results(filename: str) -> Dict:\n",
    "    \"\"\"Load results from JSON file\"\"\"\n",
    "    filepath = os.path.join('results', filename)\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "# Setup reproducibility\n",
    "setup_reproducibility()\n",
    "\n",
    "print(\"üõ†Ô∏è Utility functions initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W35e3lbBgpuf"
   },
   "source": [
    "## 4. Data Management System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset classes defined successfully!\n"
     ]
    }
   ],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    class EmotionDataset(Dataset):\n",
    "        \"\"\"Custom dataset for emotion classification\"\"\"\n",
    "\n",
    "        def __init__(self, texts, labels, tokenizer=None, vocab=None, max_length=128):\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "            self.tokenizer = tokenizer\n",
    "            self.vocab = vocab\n",
    "            self.max_length = max_length\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.texts)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            text = str(self.texts[idx])\n",
    "            label = self.labels[idx]\n",
    "\n",
    "            if self.tokenizer is not None:\n",
    "                # For transformer models\n",
    "                encoding = self.tokenizer(\n",
    "                    text,\n",
    "                    truncation=True,\n",
    "                    padding='max_length',\n",
    "                    max_length=self.max_length,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                return {\n",
    "                    'input_ids': encoding['input_ids'].flatten(),\n",
    "                    'attention_mask': encoding['attention_mask'].flatten(),\n",
    "                    'labels': torch.tensor(label, dtype=torch.long)\n",
    "                }\n",
    "            else:\n",
    "                # For traditional models (BiLSTM, CNN)\n",
    "                tokens = text.lower().split()\n",
    "                indices = [self.vocab.get(token, self.vocab.get('<unk>', 1)) for token in tokens]\n",
    "                return torch.tensor(indices), torch.tensor(label, dtype=torch.long)\n",
    "else:\n",
    "    # Fallback dataset class for non-PyTorch environments\n",
    "    class EmotionDataset:\n",
    "        \"\"\"Simple dataset for emotion classification without PyTorch\"\"\"\n",
    "\n",
    "        def __init__(self, texts, labels, tokenizer=None, vocab=None, max_length=128):\n",
    "            self.texts = texts\n",
    "            self.labels = labels\n",
    "            self.tokenizer = tokenizer\n",
    "            self.vocab = vocab\n",
    "            self.max_length = max_length\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.texts)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            text = str(self.texts[idx])\n",
    "            label = self.labels[idx]\n",
    "\n",
    "            if self.vocab is not None:\n",
    "                # For traditional models\n",
    "                tokens = text.lower().split()\n",
    "                indices = [self.vocab.get(token, self.vocab.get('<unk>', 1)) for token in tokens]\n",
    "                return indices, label\n",
    "            else:\n",
    "                return text, label\n",
    "\n",
    "def collate_fn_traditional(batch):\n",
    "    \"\"\"Collate function for traditional models\"\"\"\n",
    "    texts, labels = zip(*batch)\n",
    "    texts = pad_sequence(texts, batch_first=True, padding_value=0)\n",
    "    labels = torch.stack(labels)\n",
    "    return texts, labels\n",
    "\n",
    "def collate_fn_transformer(batch):\n",
    "    \"\"\"Collate function for transformer models\"\"\"\n",
    "    input_ids = torch.stack([item['input_ids'] for item in batch])\n",
    "    attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
    "    labels = torch.stack([item['labels'] for item in batch])\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Dataset classes defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DataManager class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class DataManager:\n",
    "    \"\"\"Unified data management system for all models\"\"\"\n",
    "\n",
    "    def __init__(self, dataset_name=\"dair-ai/emotion\"):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset = None\n",
    "        self.tokenizers = {}\n",
    "        self.vocab = None\n",
    "        self.emotion_labels = [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "\n",
    "    def load_dataset(self, use_sample=False):\n",
    "        \"\"\"Load the emotion dataset with fallback to sample data\"\"\"\n",
    "        if DATASETS_AVAILABLE and not use_sample:\n",
    "            try:\n",
    "                print(\"üìä Loading emotion dataset from HuggingFace...\")\n",
    "                self.dataset = load_dataset(self.dataset_name)\n",
    "                print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "                print(f\"   Train samples: {len(self.dataset['train'])}\")\n",
    "                print(f\"   Validation samples: {len(self.dataset['validation'])}\")\n",
    "                print(f\"   Test samples: {len(self.dataset['test'])}\")\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Failed to load HuggingFace dataset: {e}\")\n",
    "                print(\"üìù Falling back to sample data...\")\n",
    "\n",
    "        # Use sample data\n",
    "        print(\"üìä Using sample dataset...\")\n",
    "        sample_data = self._create_sample_dataset()\n",
    "\n",
    "        # Split into train/val/test\n",
    "        total_size = len(sample_data['text'])\n",
    "        train_size = int(0.7 * total_size)\n",
    "        val_size = int(0.15 * total_size)\n",
    "\n",
    "        self.dataset = {\n",
    "            'train': {\n",
    "                'text': sample_data['text'][:train_size],\n",
    "                'label': sample_data['label'][:train_size]\n",
    "            },\n",
    "            'validation': {\n",
    "                'text': sample_data['text'][train_size:train_size+val_size],\n",
    "                'label': sample_data['label'][train_size:train_size+val_size]\n",
    "            },\n",
    "            'test': {\n",
    "                'text': sample_data['text'][train_size+val_size:],\n",
    "                'label': sample_data['label'][train_size+val_size:]\n",
    "            }\n",
    "        }\n",
    "\n",
    "        print(f\"‚úÖ Sample dataset created!\")\n",
    "        print(f\"   Train samples: {len(self.dataset['train']['text'])}\")\n",
    "        print(f\"   Validation samples: {len(self.dataset['validation']['text'])}\")\n",
    "        print(f\"   Test samples: {len(self.dataset['test']['text'])}\")\n",
    "        return True\n",
    "\n",
    "    def _create_sample_dataset(self, size_per_emotion=100):\n",
    "        \"\"\"Create sample dataset when HuggingFace datasets is not available\"\"\"\n",
    "        sample_texts = {\n",
    "            0: [  # sadness\n",
    "                \"I feel so sad today\", \"This makes me really depressed\", \"I'm feeling down and blue\",\n",
    "                \"Everything seems hopeless\", \"I can't stop crying\", \"My heart is broken\",\n",
    "                \"I feel empty inside\", \"Nothing brings me joy anymore\", \"I'm overwhelmed with sorrow\",\n",
    "                \"This is devastating news\", \"I'm so disappointed\", \"Life feels meaningless\",\n",
    "                \"I'm drowning in sadness\", \"This hurts so much\", \"I feel lost and alone\"\n",
    "            ],\n",
    "            1: [  # joy\n",
    "                \"I am so happy today!\", \"This brings me great joy\", \"I'm feeling fantastic\",\n",
    "                \"What a wonderful day\", \"I'm on cloud nine\", \"This makes me smile\",\n",
    "                \"I'm bursting with happiness\", \"Life is beautiful\", \"I feel amazing\",\n",
    "                \"This is the best day ever\", \"I'm so excited\", \"Everything is perfect\",\n",
    "                \"I'm filled with joy\", \"This is incredible\", \"I'm so grateful\"\n",
    "            ],\n",
    "            2: [  # love\n",
    "                \"I love spending time with family\", \"My heart is full of love\", \"I adore this person\",\n",
    "                \"Love is in the air\", \"I cherish these moments\", \"You mean everything to me\",\n",
    "                \"I'm deeply in love\", \"This fills my heart with warmth\", \"I care about you so much\",\n",
    "                \"Love conquers all\", \"I'm so in love\", \"My heart belongs to you\",\n",
    "                \"I love you more than words\", \"This love is eternal\", \"You are my everything\"\n",
    "            ],\n",
    "            3: [  # anger\n",
    "                \"That makes me so angry!\", \"This is infuriating!\", \"I'm furious about this\",\n",
    "                \"This makes my blood boil\", \"I'm fed up with this\", \"This is absolutely outrageous\",\n",
    "                \"I can't stand this anymore\", \"This is driving me crazy\", \"I'm seeing red\",\n",
    "                \"This is completely unacceptable\", \"I'm so mad\", \"This is ridiculous\",\n",
    "                \"I'm boiling with rage\", \"This is so frustrating\", \"I'm livid\"\n",
    "            ],\n",
    "            4: [  # fear\n",
    "                \"I'm scared of what might happen\", \"This terrifies me\", \"I'm afraid of the dark\",\n",
    "                \"This gives me anxiety\", \"I'm worried about the future\", \"This is my worst nightmare\",\n",
    "                \"I'm trembling with fear\", \"This makes me nervous\", \"I'm panicking\",\n",
    "                \"This is frightening\", \"I'm so anxious\", \"This scares me\",\n",
    "                \"I'm filled with dread\", \"This is terrifying\", \"I'm so worried\"\n",
    "            ],\n",
    "            5: [  # surprise\n",
    "                \"What a surprise that was!\", \"I can't believe this happened\", \"This is unexpected\",\n",
    "                \"Wow, I didn't see that coming\", \"This is amazing news\", \"I'm shocked by this\",\n",
    "                \"This caught me off guard\", \"What an incredible turn of events\", \"This is beyond my expectations\",\n",
    "                \"I'm stunned\", \"This is so surprising\", \"I never expected this\",\n",
    "                \"What a twist\", \"This is unbelievable\", \"I'm amazed\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        texts = []\n",
    "        labels = []\n",
    "\n",
    "        for emotion_id, emotion_texts in sample_texts.items():\n",
    "            for _ in range(size_per_emotion):\n",
    "                # Randomly select and slightly modify texts\n",
    "                base_text = random.choice(emotion_texts)\n",
    "                texts.append(base_text)\n",
    "                labels.append(emotion_id)\n",
    "\n",
    "        # Shuffle the data\n",
    "        combined = list(zip(texts, labels))\n",
    "        random.shuffle(combined)\n",
    "        texts, labels = zip(*combined)\n",
    "\n",
    "        return {'text': list(texts), 'label': list(labels)}\n",
    "\n",
    "    def build_vocab(self, texts, min_freq=2):\n",
    "        \"\"\"Build vocabulary for traditional models\"\"\"\n",
    "        print(\"üî§ Building vocabulary...\")\n",
    "        word_counts = Counter()\n",
    "        for text in texts:\n",
    "            tokens = str(text).lower().split()\n",
    "            word_counts.update(tokens)\n",
    "\n",
    "        # Create vocabulary\n",
    "        vocab = {'<pad>': 0, '<unk>': 1}\n",
    "        for word, count in word_counts.items():\n",
    "            if count >= min_freq:\n",
    "                vocab[word] = len(vocab)\n",
    "\n",
    "        self.vocab = vocab\n",
    "        print(f\"‚úÖ Vocabulary built with {len(vocab)} words\")\n",
    "        return vocab\n",
    "\n",
    "    def register_tokenizer(self, model_name, tokenizer):\n",
    "        \"\"\"Register a tokenizer for a specific model\"\"\"\n",
    "        self.tokenizers[model_name] = tokenizer\n",
    "        print(f\"üîß Tokenizer registered for {model_name}\")\n",
    "\n",
    "    def get_data_loaders(self, model_type, batch_size=16, max_length=128):\n",
    "        \"\"\"Get data loaders for different model types\"\"\"\n",
    "        if self.dataset is None:\n",
    "            raise ValueError(\"Dataset not loaded. Call load_dataset() first.\")\n",
    "\n",
    "        # ‰øÆÂ§çÔºöÁ°Æ‰øùÊï∞ÊçÆÁ±ªÂûãÊ≠£Á°Æ\n",
    "        train_texts = self.dataset['train']['text']\n",
    "        train_labels = self.dataset['train']['label']\n",
    "        val_texts = self.dataset['validation']['text']\n",
    "        val_labels = self.dataset['validation']['label']\n",
    "        test_texts = self.dataset['test']['text']\n",
    "        test_labels = self.dataset['test']['label']\n",
    "\n",
    "        # ‰øÆÂ§çÔºöËΩ¨Êç¢‰∏∫ Python ÂéüÁîüÁ±ªÂûã\n",
    "        if hasattr(train_texts, 'tolist'):  # Â¶ÇÊûúÊòØ pandas Series Êàñ numpy array\n",
    "            train_texts = train_texts.tolist()\n",
    "        if hasattr(train_labels, 'tolist'):\n",
    "            train_labels = train_labels.tolist()\n",
    "        if hasattr(val_texts, 'tolist'):\n",
    "            val_texts = val_texts.tolist()\n",
    "        if hasattr(val_labels, 'tolist'):\n",
    "            val_labels = val_labels.tolist()\n",
    "        if hasattr(test_texts, 'tolist'):\n",
    "            test_texts = test_texts.tolist()\n",
    "        if hasattr(test_labels, 'tolist'):\n",
    "            test_labels = test_labels.tolist()\n",
    "\n",
    "        # ‰øÆÂ§çÔºöÁ°Æ‰øùÊâÄÊúâÊñáÊú¨ÈÉΩÊòØÂ≠óÁ¨¶‰∏≤Á±ªÂûã\n",
    "        train_texts = [str(text) for text in train_texts]\n",
    "        val_texts = [str(text) for text in val_texts]\n",
    "        test_texts = [str(text) for text in test_texts]\n",
    "\n",
    "        # ‰øÆÂ§çÔºöÁ°Æ‰øùÊâÄÊúâÊ†áÁ≠æÈÉΩÊòØÊï¥Êï∞Á±ªÂûã\n",
    "        train_labels = [int(label) for label in train_labels]\n",
    "        val_labels = [int(label) for label in val_labels]\n",
    "        test_labels = [int(label) for label in test_labels]\n",
    "\n",
    "        if model_type == 'traditional':\n",
    "            # Build vocabulary if not exists\n",
    "            if self.vocab is None:\n",
    "                all_texts = train_texts + val_texts + test_texts\n",
    "                self.build_vocab(all_texts)\n",
    "\n",
    "            # Create datasets\n",
    "            train_dataset = EmotionDataset(train_texts, train_labels, vocab=self.vocab, max_length=max_length)\n",
    "            val_dataset = EmotionDataset(val_texts, val_labels, vocab=self.vocab, max_length=max_length)\n",
    "            test_dataset = EmotionDataset(test_texts, test_labels, vocab=self.vocab, max_length=max_length)\n",
    "\n",
    "            # Create data loaders\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_traditional)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_traditional)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_traditional)\n",
    "\n",
    "        else:\n",
    "            # For transformer models\n",
    "            tokenizer = self.tokenizers.get(model_type)\n",
    "            if tokenizer is None:\n",
    "                raise ValueError(f\"Tokenizer for {model_type} not registered\")\n",
    "\n",
    "            # Create datasets\n",
    "            train_dataset = EmotionDataset(train_texts, train_labels, tokenizer=tokenizer, max_length=max_length)\n",
    "            val_dataset = EmotionDataset(val_texts, val_labels, tokenizer=tokenizer, max_length=max_length)\n",
    "            test_dataset = EmotionDataset(test_texts, test_labels, tokenizer=tokenizer, max_length=max_length)\n",
    "\n",
    "            # Create data loaders\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn_transformer)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_transformer)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn_transformer)\n",
    "\n",
    "        print(f\"‚úÖ Data loaders created for {model_type} models\")\n",
    "        return train_loader, val_loader, test_loader\n",
    "\n",
    "    def get_class_weights(self):\n",
    "        \"\"\"Calculate class weights for imbalanced dataset\"\"\"\n",
    "        if self.dataset is None:\n",
    "            raise ValueError(\"Dataset not loaded\")\n",
    "\n",
    "        train_labels = self.dataset['train']['label']\n",
    "        class_counts = Counter(train_labels)\n",
    "        total_samples = len(train_labels)\n",
    "\n",
    "        # Calculate weights (inverse frequency)\n",
    "        weights = []\n",
    "        for i in range(len(self.emotion_labels)):\n",
    "            weight = total_samples / (len(self.emotion_labels) * class_counts[i])\n",
    "            weights.append(weight)\n",
    "\n",
    "        return torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "    def get_dataset_info(self):\n",
    "        \"\"\"Get dataset statistics\"\"\"\n",
    "        if self.dataset is None:\n",
    "            return None\n",
    "\n",
    "        train_labels = self.dataset['train']['label']\n",
    "        class_counts = Counter(train_labels)\n",
    "\n",
    "        info = {\n",
    "            'total_samples': len(train_labels),\n",
    "            'num_classes': len(self.emotion_labels),\n",
    "            'class_distribution': dict(class_counts),\n",
    "            'emotion_labels': self.emotion_labels\n",
    "        }\n",
    "\n",
    "        return info\n",
    "\n",
    "print(\"‚úÖ DataManager class defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading emotion dataset from HuggingFace...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset loaded successfully!\n",
      "   Train samples: 16000\n",
      "   Validation samples: 2000\n",
      "   Test samples: 2000\n",
      "\n",
      "üìä Dataset Information:\n",
      "   Total training samples: 16000\n",
      "   Number of classes: 6\n",
      "   Emotion labels: ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
      "\n",
      "üìà Class Distribution:\n",
      "   sadness: 4666 samples (29.2%)\n",
      "   anger: 2159 samples (13.5%)\n",
      "   love: 1304 samples (8.2%)\n",
      "   surprise: 572 samples (3.6%)\n",
      "   fear: 1937 samples (12.1%)\n",
      "   joy: 5362 samples (33.5%)\n",
      "\n",
      "‚öñÔ∏è Class weights calculated: ['0.572', '0.497', '2.045', '1.235', '1.377', '4.662']\n"
     ]
    }
   ],
   "source": [
    "# Initialize data manager and load dataset\n",
    "data_manager = DataManager()\n",
    "\n",
    "# Load dataset\n",
    "if data_manager.load_dataset():\n",
    "    # Display dataset information\n",
    "    info = data_manager.get_dataset_info()\n",
    "    print(\"\\nüìä Dataset Information:\")\n",
    "    print(f\"   Total training samples: {info['total_samples']}\")\n",
    "    print(f\"   Number of classes: {info['num_classes']}\")\n",
    "    print(f\"   Emotion labels: {info['emotion_labels']}\")\n",
    "\n",
    "    print(\"\\nüìà Class Distribution:\")\n",
    "    for i, (label, count) in enumerate(info['class_distribution'].items()):\n",
    "        emotion = info['emotion_labels'][label]\n",
    "        percentage = (count / info['total_samples']) * 100\n",
    "        print(f\"   {emotion}: {count} samples ({percentage:.1f}%)\")\n",
    "\n",
    "    # Calculate class weights\n",
    "    class_weights = data_manager.get_class_weights()\n",
    "    print(f\"\\n‚öñÔ∏è Class weights calculated: {[f'{w:.3f}' for w in class_weights.tolist()]}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Failed to initialize data manager\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlHw8R9Agpug"
   },
   "source": [
    "### 4.1 Tokenizer Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Registering tokenizers for transformer models...\n",
      "üîß Tokenizer registered for roberta-base\n",
      "üîß Tokenizer registered for roberta-large\n",
      "üîß Tokenizer registered for deberta-v3-base\n",
      "üîß Tokenizer registered for distilbert-base\n",
      "üîß Tokenizer registered for electra-base\n",
      "üîß Tokenizer registered for xlnet-base\n",
      "üîß Tokenizer registered for albert-base\n",
      "\n",
      "‚úÖ Successfully registered 7/7 tokenizers\n"
     ]
    }
   ],
   "source": [
    "# Register tokenizers for different models\n",
    "print(\"üîß Registering tokenizers for transformer models...\")\n",
    "tokenizer_configs = {\n",
    "    'roberta-base': 'roberta-base',\n",
    "    'roberta-large': 'roberta-large',\n",
    "    'deberta-v3-base': 'microsoft/deberta-v3-base',\n",
    "    'distilbert-base': 'distilbert-base-uncased',\n",
    "    'electra-base': 'google/electra-base-discriminator',\n",
    "    'xlnet-base': 'xlnet-base-cased',\n",
    "    'albert-base': 'albert-base-v2'\n",
    "}\n",
    "successful_tokenizers = 0\n",
    "for model_name, model_path in tokenizer_configs.items():\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        data_manager.register_tokenizer(model_name, tokenizer)\n",
    "        successful_tokenizers += 1\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Failed to load tokenizer for {model_name}: {e}\")\n",
    "print(f\"\\n‚úÖ Successfully registered {successful_tokenizers}/{len(tokenizer_configs)} tokenizers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuKR7TQvgpug"
   },
   "source": [
    "### 4.2 Test Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing data loading for traditional models...\n",
      "üî§ Building vocabulary...\n",
      "‚úÖ Vocabulary built with 8430 words\n",
      "‚úÖ Data loaders created for traditional models\n",
      "‚úÖ Traditional model data loading successful\n",
      "   Batch text shape: torch.Size([8, 53])\n",
      "   Batch labels shape: torch.Size([8])\n",
      "   Train/Val/Test lengths: 2000/250/250\n",
      "   Vocabulary size: 8430\n",
      "\n",
      "üß™ Testing data loading for transformer models...\n",
      "   Testing with model: roberta-base\n",
      "‚úÖ Data loaders created for roberta-base models\n",
      "‚úÖ Transformer model data loading successful\n",
      "   Input IDs shape: torch.Size([4, 128])\n",
      "   Attention mask shape: torch.Size([4, 128])\n",
      "   Labels shape: torch.Size([4])\n",
      "   Batch keys: ['input_ids', 'attention_mask', 'labels']\n",
      "   Train/Val/Test lengths: 4000/500/500\n"
     ]
    }
   ],
   "source": [
    "# Test data loading for traditional models\n",
    "print(\"üß™ Testing data loading for traditional models...\")\n",
    "try:\n",
    "    train_loader, val_loader, test_loader = data_manager.get_data_loaders('traditional', batch_size=8)\n",
    "\n",
    "    # Verify loaders are created\n",
    "    if not all([train_loader, val_loader, test_loader]):\n",
    "        raise ValueError(\"One or more data loaders is None\")\n",
    "\n",
    "    # Test a batch\n",
    "    sample_batch = next(iter(train_loader))\n",
    "\n",
    "    # Handle different batch formats\n",
    "    if isinstance(sample_batch, (list, tuple)) and len(sample_batch) == 2:\n",
    "        texts, labels = sample_batch\n",
    "        print(f\"‚úÖ Traditional model data loading successful\")\n",
    "\n",
    "        if hasattr(texts, 'shape'):\n",
    "            batch_shape_info = texts.shape\n",
    "        else:\n",
    "            text_length = len(texts) if hasattr(texts, \"__len__\") else \"Unknown\"\n",
    "            batch_shape_info = f'Type: {type(texts)}, Length: {text_length}'\n",
    "\n",
    "        print(f\"   Batch text shape: {batch_shape_info}\")\n",
    "\n",
    "        if hasattr(labels, 'shape'):\n",
    "            label_shape_info = labels.shape\n",
    "        else:\n",
    "            label_length = len(labels) if hasattr(labels, \"__len__\") else \"Unknown\"\n",
    "            label_shape_info = f'Type: {type(labels)}, Length: {label_length}'\n",
    "\n",
    "        print(f\"   Batch labels shape: {label_shape_info}\")\n",
    "\n",
    "        print(f\"   Train/Val/Test lengths: {len(train_loader)}/{len(val_loader)}/{len(test_loader)}\")\n",
    "\n",
    "        if hasattr(data_manager, 'vocab') and data_manager.vocab:\n",
    "            print(f\"   Vocabulary size: {len(data_manager.vocab)}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Traditional model data loading successful\")\n",
    "        print(f\"   Batch type: {type(sample_batch)}\")\n",
    "        print(f\"   Batch info: {str(sample_batch)[:100]}...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Traditional model data loading failed: {e}\")\n",
    "    print(f\"   Error type: {type(e).__name__}\")\n",
    "    print(f\"   Debug: Has vocab = {hasattr(data_manager, 'vocab')}\")\n",
    "\n",
    "# Test data loading for transformer models (if tokenizers are available)\n",
    "if hasattr(data_manager, 'tokenizers') and data_manager.tokenizers:\n",
    "    print(\"\\nüß™ Testing data loading for transformer models...\")\n",
    "    try:\n",
    "        # Test with first available tokenizer\n",
    "        available_models = list(data_manager.tokenizers.keys())\n",
    "        first_model = available_models[0]\n",
    "        print(f\"   Testing with model: {first_model}\")\n",
    "\n",
    "        train_loader, val_loader, test_loader = data_manager.get_data_loaders(first_model, batch_size=4)\n",
    "\n",
    "        # Verify loaders\n",
    "        if not all([train_loader, val_loader, test_loader]):\n",
    "            raise ValueError(\"One or more data loaders is None\")\n",
    "\n",
    "        # Test a batch\n",
    "        sample_batch = next(iter(train_loader))\n",
    "        print(f\"‚úÖ Transformer model data loading successful\")\n",
    "\n",
    "        if isinstance(sample_batch, dict):\n",
    "            if 'input_ids' in sample_batch:\n",
    "                print(f\"   Input IDs shape: {sample_batch['input_ids'].shape}\")\n",
    "            if 'attention_mask' in sample_batch:\n",
    "                print(f\"   Attention mask shape: {sample_batch['attention_mask'].shape}\")\n",
    "            if 'labels' in sample_batch:\n",
    "                print(f\"   Labels shape: {sample_batch['labels'].shape}\")\n",
    "            print(f\"   Batch keys: {list(sample_batch.keys())}\")\n",
    "        else:\n",
    "            print(f\"   Batch type: {type(sample_batch)}\")\n",
    "\n",
    "        print(f\"   Train/Val/Test lengths: {len(train_loader)}/{len(val_loader)}/{len(test_loader)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Transformer model data loading failed: {e}\")\n",
    "        print(f\"   Error type: {type(e).__name__}\")\n",
    "        print(f\"   Available models: {list(data_manager.tokenizers.keys())}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No tokenizers available for transformer model testing\")\n",
    "    print(\"   Check if tokenizers are properly initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmtfkeLpgpug"
   },
   "source": [
    "## 5. Model Architecture Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data structures defined successfully!\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    \"\"\"Configuration class for models\"\"\"\n",
    "    name: str\n",
    "    model_type: str  # \"traditional\", \"transformer\"\n",
    "    num_labels: int = 6\n",
    "    vocab_size: Optional[int] = None\n",
    "    embedding_dim: int = 100\n",
    "    hidden_dim: int = 256\n",
    "    num_layers: int = 2\n",
    "    dropout: float = 0.5\n",
    "    learning_rate: float = 2e-5\n",
    "    batch_size: int = 16\n",
    "    max_epochs: int = 3\n",
    "    pretrained_model: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class TrainingResult:\n",
    "    \"\"\"Training result data structure\"\"\"\n",
    "    model_name: str\n",
    "    accuracy: float\n",
    "    f1_macro: float\n",
    "    f1_weighted: float\n",
    "    precision_macro: float\n",
    "    recall_macro: float\n",
    "    confusion_matrix: np.ndarray\n",
    "    training_time: float\n",
    "    inference_time: float\n",
    "    model_size: int\n",
    "    training_history: Dict\n",
    "    classification_report: str\n",
    "\n",
    "print(\"‚úÖ Data structures defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ BaseEmotionModel abstract class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class BaseEmotionModel(ABC, nn.Module):\n",
    "    \"\"\"Abstract base class for all emotion classification models\"\"\"\n",
    "\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model_name = config.name\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass of the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def get_config(self) -> Dict:\n",
    "        \"\"\"Get model configuration\"\"\"\n",
    "        return {\n",
    "            'name': self.model_name,\n",
    "            'type': self.config.model_type,\n",
    "            'num_parameters': sum(p.numel() for p in self.parameters()),\n",
    "            'config': self.config.__dict__\n",
    "        }\n",
    "\n",
    "    def save_model(self, path: str):\n",
    "        \"\"\"Save model state and configuration\"\"\"\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        torch.save({\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'config': self.config,\n",
    "            'model_info': self.get_config()\n",
    "        }, path)\n",
    "        print(f\"üíæ Model saved to {path}\")\n",
    "\n",
    "    def load_model(self, path: str):\n",
    "        \"\"\"Load model state\"\"\"\n",
    "        checkpoint = torch.load(path, map_location='cpu')\n",
    "        self.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f\"üìÇ Model loaded from {path}\")\n",
    "        return checkpoint.get('model_info', {})\n",
    "\n",
    "print(\"‚úÖ BaseEmotionModel abstract class defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Traditional model architectures defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Traditional Models Implementation\n",
    "\n",
    "class BiLSTMAttention(BaseEmotionModel):\n",
    "    \"\"\"BiLSTM with Attention mechanism for emotion classification\"\"\"\n",
    "\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.embedding = nn.Embedding(config.vocab_size, config.embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            config.embedding_dim,\n",
    "            config.hidden_dim,\n",
    "            num_layers=config.num_layers,\n",
    "            bidirectional=True,\n",
    "            dropout=config.dropout if config.num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Linear(config.hidden_dim * 2, 1)\n",
    "\n",
    "        # Classification head\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.classifier = nn.Linear(config.hidden_dim * 2, config.num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len)\n",
    "        embedded = self.dropout(self.embedding(x))  # (batch_size, seq_len, embedding_dim)\n",
    "\n",
    "        # LSTM forward pass\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)  # (batch_size, seq_len, hidden_dim*2)\n",
    "\n",
    "        # Attention mechanism\n",
    "        attention_weights = torch.softmax(self.attention(lstm_out).squeeze(2), dim=1)  # (batch_size, seq_len)\n",
    "        context_vector = torch.bmm(attention_weights.unsqueeze(1), lstm_out).squeeze(1)  # (batch_size, hidden_dim*2)\n",
    "\n",
    "        # Classification\n",
    "        output = self.classifier(self.dropout(context_vector))\n",
    "        return output\n",
    "\n",
    "class CNNEmotionClassifier(BaseEmotionModel):\n",
    "    \"\"\"CNN model for emotion classification\"\"\"\n",
    "\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.embedding = nn.Embedding(config.vocab_size, config.embedding_dim, padding_idx=0)\n",
    "\n",
    "        # Multiple filter sizes for n-gram capture\n",
    "        self.filter_sizes = [2, 3, 4, 5]\n",
    "        self.num_filters = config.hidden_dim // len(self.filter_sizes)\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(1, self.num_filters, (fs, config.embedding_dim))\n",
    "            for fs in self.filter_sizes\n",
    "        ])\n",
    "\n",
    "        # Classification head\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.classifier = nn.Linear(len(self.filter_sizes) * self.num_filters, config.num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len)\n",
    "        embedded = self.embedding(x).unsqueeze(1)  # (batch_size, 1, seq_len, embedding_dim)\n",
    "\n",
    "        # Apply convolutions\n",
    "        conv_outputs = []\n",
    "        for conv in self.convs:\n",
    "            conv_out = torch.relu(conv(embedded)).squeeze(3)  # (batch_size, num_filters, new_seq_len)\n",
    "            pooled = torch.max_pool1d(conv_out, conv_out.size(2)).squeeze(2)  # (batch_size, num_filters)\n",
    "            conv_outputs.append(pooled)\n",
    "\n",
    "        # Concatenate all conv outputs\n",
    "        concatenated = torch.cat(conv_outputs, dim=1)  # (batch_size, total_filters)\n",
    "\n",
    "        # Classification\n",
    "        output = self.classifier(self.dropout(concatenated))\n",
    "        return output\n",
    "\n",
    "print(\"‚úÖ Traditional model architectures defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Transformer model wrapper defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Transformer Model Wrapper\n",
    "\n",
    "class TransformerEmotionModel(BaseEmotionModel):\n",
    "    \"\"\"Wrapper for transformer-based emotion classification models\"\"\"\n",
    "\n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__(config)\n",
    "\n",
    "        if config.pretrained_model is None:\n",
    "            raise ValueError(\"Pretrained model path must be specified for transformer models\")\n",
    "\n",
    "        try:\n",
    "            self.transformer = AutoModelForSequenceClassification.from_pretrained(\n",
    "                config.pretrained_model,\n",
    "                num_labels=config.num_labels,\n",
    "                ignore_mismatched_sizes=True\n",
    "            )\n",
    "            print(f\"‚úÖ Loaded transformer model: {config.pretrained_model}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load transformer model {config.pretrained_model}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        \"\"\"Forward pass for transformer models\"\"\"\n",
    "        outputs = self.transformer(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self) -> Dict:\n",
    "        \"\"\"Get model configuration including transformer config\"\"\"\n",
    "        base_config = super().get_config()\n",
    "        base_config['transformer_config'] = self.transformer.config.to_dict()\n",
    "        return base_config\n",
    "\n",
    "print(\"‚úÖ Transformer model wrapper defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ModelFactory class defined successfully!\n",
      "üìã Available models: ['bilstm-attention', 'cnn', 'roberta-base', 'roberta-large', 'deberta-v3-base', 'distilbert-base', 'electra-base', 'xlnet-base', 'albert-base']\n"
     ]
    }
   ],
   "source": [
    "class ModelFactory:\n",
    "    \"\"\"Factory class for creating different emotion classification models\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_available_models() -> List[str]:\n",
    "        \"\"\"Get list of available model types\"\"\"\n",
    "        return [\n",
    "            'bilstm-attention',\n",
    "            'cnn',\n",
    "            'roberta-base',\n",
    "            'roberta-large',\n",
    "            'deberta-v3-base',\n",
    "            'distilbert-base',\n",
    "            'electra-base',\n",
    "            'xlnet-base',\n",
    "            'albert-base'\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def create_model(model_name: str, vocab_size: Optional[int] = None) -> BaseEmotionModel:\n",
    "        \"\"\"Create a model instance based on model name\"\"\"\n",
    "\n",
    "        if model_name == 'bilstm-attention':\n",
    "            if vocab_size is None:\n",
    "                raise ValueError(\"vocab_size must be provided for BiLSTM model\")\n",
    "            config = ModelConfig(\n",
    "                name='BiLSTM-Attention',\n",
    "                model_type='traditional',\n",
    "                vocab_size=vocab_size,\n",
    "                embedding_dim=100,\n",
    "                hidden_dim=256,\n",
    "                num_layers=2,\n",
    "                dropout=0.5\n",
    "            )\n",
    "            return BiLSTMAttention(config)\n",
    "\n",
    "        elif model_name == 'cnn':\n",
    "            if vocab_size is None:\n",
    "                raise ValueError(\"vocab_size must be provided for CNN model\")\n",
    "            config = ModelConfig(\n",
    "                name='CNN-Emotion',\n",
    "                model_type='traditional',\n",
    "                vocab_size=vocab_size,\n",
    "                embedding_dim=100,\n",
    "                hidden_dim=256,\n",
    "                dropout=0.5\n",
    "            )\n",
    "            return CNNEmotionClassifier(config)\n",
    "\n",
    "        elif model_name in ['roberta-base', 'roberta-large', 'deberta-v3-base',\n",
    "                           'distilbert-base', 'electra-base', 'xlnet-base', 'albert-base']:\n",
    "\n",
    "            # Map model names to HuggingFace model paths\n",
    "            model_paths = {\n",
    "                'roberta-base': 'roberta-base',\n",
    "                'roberta-large': 'roberta-large',\n",
    "                'deberta-v3-base': 'microsoft/deberta-v3-base',\n",
    "                'distilbert-base': 'distilbert-base-uncased',\n",
    "                'electra-base': 'google/electra-base-discriminator',\n",
    "                'xlnet-base': 'xlnet-base-cased',\n",
    "                'albert-base': 'albert-base-v2'\n",
    "            }\n",
    "\n",
    "            config = ModelConfig(\n",
    "                name=model_name.upper(),\n",
    "                model_type='transformer',\n",
    "                pretrained_model=model_paths[model_name],\n",
    "                learning_rate=2e-5,\n",
    "                batch_size=16\n",
    "            )\n",
    "            return TransformerEmotionModel(config)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model name: {model_name}. Available models: {ModelFactory.get_available_models()}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_model_info(model_name: str) -> Dict:\n",
    "        \"\"\"Get information about a specific model\"\"\"\n",
    "        model_info = {\n",
    "            'bilstm-attention': {\n",
    "                'description': 'Bidirectional LSTM with attention mechanism',\n",
    "                'type': 'traditional',\n",
    "                'parameters': '~2M (depends on vocab size)',\n",
    "                'strengths': 'Good for sequential patterns, attention mechanism'\n",
    "            },\n",
    "            'cnn': {\n",
    "                'description': 'Convolutional Neural Network with multiple filter sizes',\n",
    "                'type': 'traditional',\n",
    "                'parameters': '~1M (depends on vocab size)',\n",
    "                'strengths': 'Fast training, good for local patterns'\n",
    "            },\n",
    "            'roberta-base': {\n",
    "                'description': 'RoBERTa base model (125M parameters)',\n",
    "                'type': 'transformer',\n",
    "                'parameters': '125M',\n",
    "                'strengths': 'Strong contextual understanding, robust training'\n",
    "            },\n",
    "            'roberta-large': {\n",
    "                'description': 'RoBERTa large model (355M parameters)',\n",
    "                'type': 'transformer',\n",
    "                'parameters': '355M',\n",
    "                'strengths': 'Best performance, large capacity'\n",
    "            },\n",
    "            'deberta-v3-base': {\n",
    "                'description': 'DeBERTa v3 base with enhanced attention',\n",
    "                'type': 'transformer',\n",
    "                'parameters': '184M',\n",
    "                'strengths': 'Enhanced attention mechanism, strong performance'\n",
    "            },\n",
    "            'distilbert-base': {\n",
    "                'description': 'Distilled BERT for efficiency',\n",
    "                'type': 'transformer',\n",
    "                'parameters': '66M',\n",
    "                'strengths': 'Fast inference, good performance/size ratio'\n",
    "            },\n",
    "            'electra-base': {\n",
    "                'description': 'ELECTRA discriminator model',\n",
    "                'type': 'transformer',\n",
    "                'parameters': '110M',\n",
    "                'strengths': 'Efficient pre-training, good downstream performance'\n",
    "            },\n",
    "            'xlnet-base': {\n",
    "                'description': 'XLNet with permutation language modeling',\n",
    "                'type': 'transformer',\n",
    "                'parameters': '117M',\n",
    "                'strengths': 'Bidirectional context, autoregressive benefits'\n",
    "            },\n",
    "            'albert-base': {\n",
    "                'description': 'ALBERT with parameter sharing',\n",
    "                'type': 'transformer',\n",
    "                'parameters': '12M',\n",
    "                'strengths': 'Parameter efficient, good performance'\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return model_info.get(model_name, {'description': 'Unknown model'})\n",
    "\n",
    "print(\"‚úÖ ModelFactory class defined successfully!\")\n",
    "print(f\"üìã Available models: {ModelFactory.get_available_models()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUtLPhQrgpuh"
   },
   "source": [
    "### 5.1 Test Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing model creation...\n",
      "\n",
      "üìù Using vocabulary size: 8430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ BiLSTM model created: 3,156,735 parameters\n",
      "‚úÖ CNN model created: 934,398 parameters\n",
      "\n",
      "ü§ñ Testing transformer model creation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded transformer model: roberta-base\n",
      "‚úÖ roberta-base created: 124,650,246 parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded transformer model: distilbert-base-uncased\n",
      "‚úÖ distilbert-base created: 66,958,086 parameters\n",
      "\n",
      "üìä Model Information Summary:\n",
      "   bilstm-attention: Bidirectional LSTM with attention mechanism (~2M (depends on vocab size) params)\n",
      "   cnn: Convolutional Neural Network with multiple filter sizes (~1M (depends on vocab size) params)\n",
      "   roberta-base: RoBERTa base model (125M parameters) (125M params)\n",
      "   roberta-large: RoBERTa large model (355M parameters) (355M params)\n",
      "   deberta-v3-base: DeBERTa v3 base with enhanced attention (184M params)\n",
      "\n",
      "‚úÖ Model creation tests completed!\n"
     ]
    }
   ],
   "source": [
    "# Test model creation with vocabulary building\n",
    "print(\"üß™ Testing model creation...\")\n",
    "\n",
    "# Ensure vocabulary is built for traditional models\n",
    "if data_manager.dataset is not None and data_manager.vocab is None:\n",
    "    print(\"üî§ Building vocabulary for model creation tests...\")\n",
    "    # Get all text data for vocabulary building\n",
    "    all_texts = []\n",
    "    all_texts.extend(list(data_manager.dataset['train']['text']))\n",
    "    all_texts.extend(list(data_manager.dataset['validation']['text']))\n",
    "    all_texts.extend(list(data_manager.dataset['test']['text']))\n",
    "\n",
    "    data_manager.build_vocab(all_texts)\n",
    "    print(f\"‚úÖ Vocabulary built with {len(data_manager.vocab)} words\")\n",
    "\n",
    "# Test traditional models (need vocab size)\n",
    "if data_manager.vocab is not None:\n",
    "    vocab_size = len(data_manager.vocab)\n",
    "    print(f\"\\nüìù Using vocabulary size: {vocab_size}\")\n",
    "\n",
    "    try:\n",
    "        # Test BiLSTM creation\n",
    "        bilstm_model = ModelFactory.create_model('bilstm-attention', vocab_size=vocab_size)\n",
    "        print(f\"‚úÖ BiLSTM model created: {get_model_size(bilstm_model):,} parameters\")\n",
    "\n",
    "        # Test CNN creation\n",
    "        cnn_model = ModelFactory.create_model('cnn', vocab_size=vocab_size)\n",
    "        print(f\"‚úÖ CNN model created: {get_model_size(cnn_model):,} parameters\")\n",
    "\n",
    "        # Clean up traditional models to save memory\n",
    "        del bilstm_model, cnn_model\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Traditional model creation failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Vocabulary not available, skipping traditional model tests\")\n",
    "\n",
    "# Test transformer models (if tokenizers are available)\n",
    "if data_manager.tokenizers:\n",
    "    print(\"\\nü§ñ Testing transformer model creation...\")\n",
    "\n",
    "    # Test a few transformer models\n",
    "    test_models = ['roberta-base', 'distilbert-base']\n",
    "\n",
    "    for model_name in test_models:\n",
    "        try:\n",
    "            model = ModelFactory.create_model(model_name)\n",
    "            print(f\"‚úÖ {model_name} created: {get_model_size(model):,} parameters\")\n",
    "\n",
    "            # Clean up to save memory\n",
    "            del model\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è {model_name} creation failed: {e}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No tokenizers available, skipping transformer model tests\")\n",
    "\n",
    "# Display model information\n",
    "print(\"\\nüìä Model Information Summary:\")\n",
    "for model_name in ModelFactory.get_available_models()[:5]:  # Show first 5\n",
    "    info = ModelFactory.get_model_info(model_name)\n",
    "    print(f\"   {model_name}: {info['description']} ({info.get('parameters', 'Unknown')} params)\")\n",
    "\n",
    "print(\"\\n‚úÖ Model creation tests completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P7r1fCANgpui"
   },
   "source": [
    "## 6. Training Management System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TrainingManager class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class TrainingManager:\n",
    "    \"\"\"Unified training manager for all emotion classification models\"\"\"\n",
    "\n",
    "    def __init__(self, device=None):\n",
    "        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.models = {}\n",
    "        self.training_history = {}\n",
    "        self.results = {}\n",
    "\n",
    "        print(f\"üöÄ TrainingManager initialized on device: {self.device}\")\n",
    "\n",
    "    def train_traditional_model(self, model: BaseEmotionModel, train_loader, val_loader,\n",
    "                              epochs=3, learning_rate=1e-3, class_weights=None):\n",
    "        \"\"\"Train traditional models (BiLSTM, CNN)\"\"\"\n",
    "        model.to(self.device)\n",
    "        model.train()\n",
    "\n",
    "        # Setup optimizer and loss function\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        if class_weights is not None:\n",
    "            criterion = nn.CrossEntropyLoss(weight=class_weights.to(self.device))\n",
    "        else:\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Training history\n",
    "        history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_accuracy': [],\n",
    "            'val_f1': []\n",
    "        }\n",
    "\n",
    "        best_val_f1 = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        print(f\"üèãÔ∏è Training {model.model_name} for {epochs} epochs...\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
    "\n",
    "            for batch in train_pbar:\n",
    "                texts, labels = batch\n",
    "                texts, labels = texts.to(self.device), labels.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(texts)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    texts, labels = batch\n",
    "                    texts, labels = texts.to(self.device), labels.to(self.device)\n",
    "\n",
    "                    outputs = model(texts)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    preds = torch.argmax(outputs, dim=1)\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "            val_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "            # Update history\n",
    "            history['train_loss'].append(avg_train_loss)\n",
    "            history['val_loss'].append(avg_val_loss)\n",
    "            history['val_accuracy'].append(val_accuracy)\n",
    "            history['val_f1'].append(val_f1)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, \"\n",
    "                  f\"Val Acc: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "            # Save best model\n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                model.save_model(f'models/{model.model_name.lower().replace(\"-\", \"_\")}_best.pt')\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"‚úÖ Training completed in {format_time(training_time)}\")\n",
    "\n",
    "        return history, training_time\n",
    "\n",
    "    def train_transformer_model(self, model: TransformerEmotionModel, train_loader, val_loader,\n",
    "                              epochs=3, learning_rate=2e-5, class_weights=None):\n",
    "        \"\"\"Train transformer models\"\"\"\n",
    "        model.to(self.device)\n",
    "        model.train()\n",
    "\n",
    "        # Setup optimizer and scheduler\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "        total_steps = len(train_loader) * epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=int(0.1 * total_steps),\n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "\n",
    "        # Training history\n",
    "        history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_accuracy': [],\n",
    "            'val_f1': []\n",
    "        }\n",
    "\n",
    "        best_val_f1 = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        print(f\"ü§ñ Training {model.model_name} for {epochs} epochs...\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
    "\n",
    "            for batch in train_pbar:\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                labels = batch['labels'].to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "                train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "            avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    input_ids = batch['input_ids'].to(self.device)\n",
    "                    attention_mask = batch['attention_mask'].to(self.device)\n",
    "                    labels = batch['labels'].to(self.device)\n",
    "\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                    loss = outputs.loss\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    preds = torch.argmax(outputs.logits, dim=1)\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            val_accuracy = accuracy_score(all_labels, all_preds)\n",
    "            val_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "            # Update history\n",
    "            history['train_loss'].append(avg_train_loss)\n",
    "            history['val_loss'].append(avg_val_loss)\n",
    "            history['val_accuracy'].append(val_accuracy)\n",
    "            history['val_f1'].append(val_f1)\n",
    "\n",
    "            print(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, \"\n",
    "                  f\"Val Acc: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")\n",
    "\n",
    "            # Save best model\n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                model.save_model(f'models/{model.model_name.lower().replace(\"-\", \"_\")}_best.pt')\n",
    "\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"‚úÖ Training completed in {format_time(training_time)}\")\n",
    "\n",
    "        return history, training_time\n",
    "\n",
    "    def train_model(self, model_name: str, data_manager: DataManager,\n",
    "                   epochs=3, batch_size=16, learning_rate=None):\n",
    "        \"\"\"Train a specific model\"\"\"\n",
    "        print(f\"\\nüéØ Starting training for {model_name}...\")\n",
    "\n",
    "        try:\n",
    "            # Create model\n",
    "            if model_name in ['bilstm-attention', 'cnn']:\n",
    "                if data_manager.vocab is None:\n",
    "                    raise ValueError(\"Vocabulary not built for traditional models\")\n",
    "                model = ModelFactory.create_model(model_name, vocab_size=len(data_manager.vocab))\n",
    "\n",
    "                # Get data loaders\n",
    "                train_loader, val_loader, test_loader = data_manager.get_data_loaders(\n",
    "                    'traditional', batch_size=batch_size\n",
    "                )\n",
    "\n",
    "                # Train model\n",
    "                lr = learning_rate if learning_rate else 1e-3\n",
    "                class_weights = data_manager.get_class_weights()\n",
    "                history, training_time = self.train_traditional_model(\n",
    "                    model, train_loader, val_loader, epochs, lr, class_weights\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                # Transformer model\n",
    "                if model_name not in data_manager.tokenizers:\n",
    "                    raise ValueError(f\"Tokenizer for {model_name} not registered\")\n",
    "\n",
    "                model = ModelFactory.create_model(model_name)\n",
    "\n",
    "                # Get data loaders\n",
    "                train_loader, val_loader, test_loader = data_manager.get_data_loaders(\n",
    "                    model_name, batch_size=batch_size\n",
    "                )\n",
    "\n",
    "                # Train model\n",
    "                lr = learning_rate if learning_rate else 2e-5\n",
    "                history, training_time = self.train_transformer_model(\n",
    "                    model, train_loader, val_loader, epochs, lr\n",
    "                )\n",
    "\n",
    "            # Store results\n",
    "            self.models[model_name] = model\n",
    "            self.training_history[model_name] = history\n",
    "\n",
    "            print(f\"‚úÖ {model_name} training completed successfully!\")\n",
    "            return model, history, training_time\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Training failed for {model_name}: {e}\")\n",
    "            return None, None, 0\n",
    "\n",
    "    def train_multiple_models(self, model_names: List[str], data_manager: DataManager,\n",
    "                            epochs=3, batch_size=16):\n",
    "        \"\"\"Train multiple models sequentially\"\"\"\n",
    "        print(f\"üöÄ Starting batch training for {len(model_names)} models...\")\n",
    "\n",
    "        results = {}\n",
    "        total_start_time = time.time()\n",
    "\n",
    "        for i, model_name in enumerate(model_names, 1):\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Training Model {i}/{len(model_names)}: {model_name.upper()}\")\n",
    "            print(f\"{'='*60}\")\n",
    "\n",
    "            model, history, training_time = self.train_model(\n",
    "                model_name, data_manager, epochs, batch_size\n",
    "            )\n",
    "\n",
    "            if model is not None:\n",
    "                results[model_name] = {\n",
    "                    'model': model,\n",
    "                    'history': history,\n",
    "                    'training_time': training_time,\n",
    "                    'status': 'success'\n",
    "                }\n",
    "            else:\n",
    "                results[model_name] = {\n",
    "                    'status': 'failed'\n",
    "                }\n",
    "\n",
    "            # Clean up GPU memory\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        total_time = time.time() - total_start_time\n",
    "        successful_models = sum(1 for r in results.values() if r['status'] == 'success')\n",
    "\n",
    "        print(f\"\\nüéâ Batch training completed!\")\n",
    "        print(f\"   Successful models: {successful_models}/{len(model_names)}\")\n",
    "        print(f\"   Total time: {format_time(total_time)}\")\n",
    "\n",
    "        return results\n",
    "\n",
    "print(\"‚úÖ TrainingManager class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkCsXL3rgpui"
   },
   "source": [
    "### 6.1 Test Training System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ TrainingManager initialized on device: cuda\n",
      "üîß Training manager ready on cuda\n",
      "üìä Available models for training: ['bilstm-attention', 'cnn', 'roberta-base', 'roberta-large', 'deberta-v3-base', 'distilbert-base', 'electra-base', 'xlnet-base', 'albert-base']\n",
      "‚úÖ Dataset loaded and ready for training\n",
      "   Vocabulary size: 8430\n",
      "   Registered tokenizers: ['roberta-base', 'roberta-large', 'deberta-v3-base', 'distilbert-base', 'electra-base', 'xlnet-base', 'albert-base']\n"
     ]
    }
   ],
   "source": [
    "# Initialize training manager\n",
    "trainer = TrainingManager()\n",
    "\n",
    "print(f\"üîß Training manager ready on {trainer.device}\")\n",
    "print(f\"üìä Available models for training: {ModelFactory.get_available_models()}\")\n",
    "\n",
    "# Check if we have the necessary data\n",
    "if data_manager.dataset is not None:\n",
    "    print(\"‚úÖ Dataset loaded and ready for training\")\n",
    "    print(f\"   Vocabulary size: {len(data_manager.vocab) if data_manager.vocab else 'Not built'}\")\n",
    "    print(f\"   Registered tokenizers: {list(data_manager.tokenizers.keys())}\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset not loaded. Please run the data loading cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySPAt3XJgpui"
   },
   "source": [
    "## 7. Evaluation and Analysis System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ EvaluationManager class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class EvaluationManager:\n",
    "    \"\"\"Comprehensive evaluation system for emotion classification models\"\"\"\n",
    "\n",
    "    def __init__(self, emotion_labels=None):\n",
    "        self.emotion_labels = emotion_labels or [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "        self.results = {}\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        print(f\"üìà EvaluationManager initialized with {len(self.emotion_labels)} emotion classes\")\n",
    "\n",
    "    def evaluate_traditional_model(self, model: BaseEmotionModel, test_loader, model_name: str):\n",
    "        \"\"\"Evaluate traditional models (BiLSTM, CNN)\"\"\"\n",
    "        model.to(self.device)\n",
    "        model.eval()\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        inference_times = []\n",
    "\n",
    "        print(f\"üîç Evaluating {model_name} on test set...\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "                texts, labels = batch\n",
    "                texts, labels = texts.to(self.device), labels.to(self.device)\n",
    "\n",
    "                # Measure inference time\n",
    "                start_time = time.time()\n",
    "                outputs = model(texts)\n",
    "                inference_time = time.time() - start_time\n",
    "                inference_times.append(inference_time)\n",
    "\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        return self._calculate_metrics(all_labels, all_preds, model_name, inference_times)\n",
    "\n",
    "    def evaluate_transformer_model(self, model: TransformerEmotionModel, test_loader, model_name: str):\n",
    "        \"\"\"Evaluate transformer models\"\"\"\n",
    "        model.to(self.device)\n",
    "        model.eval()\n",
    "\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        inference_times = []\n",
    "\n",
    "        print(f\"ü§ñ Evaluating {model_name} on test set...\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                labels = batch['labels'].to(self.device)\n",
    "\n",
    "                # Measure inference time\n",
    "                start_time = time.time()\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                inference_time = time.time() - start_time\n",
    "                inference_times.append(inference_time)\n",
    "\n",
    "                preds = torch.argmax(outputs.logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        return self._calculate_metrics(all_labels, all_preds, model_name, inference_times)\n",
    "\n",
    "    def _calculate_metrics(self, true_labels, pred_labels, model_name, inference_times):\n",
    "        \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
    "        # Basic metrics\n",
    "        accuracy = accuracy_score(true_labels, pred_labels)\n",
    "        f1_macro = f1_score(true_labels, pred_labels, average='macro')\n",
    "        f1_weighted = f1_score(true_labels, pred_labels, average='weighted')\n",
    "        precision_macro = precision_score(true_labels, pred_labels, average='macro')\n",
    "        recall_macro = recall_score(true_labels, pred_labels, average='macro')\n",
    "\n",
    "        # Per-class metrics\n",
    "        precision_per_class = precision_score(true_labels, pred_labels, average=None)\n",
    "        recall_per_class = recall_score(true_labels, pred_labels, average=None)\n",
    "        f1_per_class = f1_score(true_labels, pred_labels, average=None)\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "        # Classification report\n",
    "        class_report = classification_report(\n",
    "            true_labels, pred_labels,\n",
    "            target_names=self.emotion_labels,\n",
    "            output_dict=True\n",
    "        )\n",
    "\n",
    "        # Timing metrics\n",
    "        avg_inference_time = np.mean(inference_times)\n",
    "        total_inference_time = np.sum(inference_times)\n",
    "\n",
    "        # Create result dictionary\n",
    "        result = {\n",
    "            'model_name': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_macro': f1_macro,\n",
    "            'f1_weighted': f1_weighted,\n",
    "            'precision_macro': precision_macro,\n",
    "            'recall_macro': recall_macro,\n",
    "            'precision_per_class': precision_per_class.tolist(),\n",
    "            'recall_per_class': recall_per_class.tolist(),\n",
    "            'f1_per_class': f1_per_class.tolist(),\n",
    "            'confusion_matrix': cm.tolist(),\n",
    "            'classification_report': class_report,\n",
    "            'avg_inference_time': avg_inference_time,\n",
    "            'total_inference_time': total_inference_time,\n",
    "            'samples_evaluated': len(true_labels)\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "    def evaluate_model(self, model: BaseEmotionModel, test_loader, model_name: str, model_type: str):\n",
    "        \"\"\"Evaluate a single model\"\"\"\n",
    "        print(f\"\\nüìä Evaluating {model_name}...\")\n",
    "\n",
    "        try:\n",
    "            if model_type == 'traditional':\n",
    "                result = self.evaluate_traditional_model(model, test_loader, model_name)\n",
    "            else:\n",
    "                result = self.evaluate_transformer_model(model, test_loader, model_name)\n",
    "\n",
    "            # Store result\n",
    "            self.results[model_name] = result\n",
    "\n",
    "            # Print summary\n",
    "            print(f\"‚úÖ {model_name} Evaluation Results:\")\n",
    "            print(f\"   Accuracy: {result['accuracy']:.4f}\")\n",
    "            print(f\"   F1-Macro: {result['f1_macro']:.4f}\")\n",
    "            print(f\"   F1-Weighted: {result['f1_weighted']:.4f}\")\n",
    "            print(f\"   Avg Inference Time: {result['avg_inference_time']*1000:.2f}ms per batch\")\n",
    "\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Evaluation failed for {model_name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def evaluate_all_models(self, models_dict: Dict, data_manager: DataManager, batch_size=16):\n",
    "        \"\"\"Evaluate all trained models\"\"\"\n",
    "        print(f\"üéØ Starting comprehensive evaluation of {len(models_dict)} models...\")\n",
    "\n",
    "        evaluation_results = {}\n",
    "\n",
    "        for model_name, model_info in models_dict.items():\n",
    "            if model_info['status'] != 'success':\n",
    "                print(f\"‚ö†Ô∏è Skipping {model_name} (training failed)\")\n",
    "                continue\n",
    "\n",
    "            model = model_info['model']\n",
    "\n",
    "            # Get appropriate test loader\n",
    "            if model_name in ['bilstm-attention', 'cnn']:\n",
    "                _, _, test_loader = data_manager.get_data_loaders('traditional', batch_size=batch_size)\n",
    "                model_type = 'traditional'\n",
    "            else:\n",
    "                _, _, test_loader = data_manager.get_data_loaders(model_name, batch_size=batch_size)\n",
    "                model_type = 'transformer'\n",
    "\n",
    "            # Evaluate model\n",
    "            result = self.evaluate_model(model, test_loader, model_name, model_type)\n",
    "\n",
    "            if result is not None:\n",
    "                # Add training information\n",
    "                result['training_time'] = model_info.get('training_time', 0)\n",
    "                result['model_size'] = get_model_size(model)\n",
    "                evaluation_results[model_name] = result\n",
    "\n",
    "            # Clean up GPU memory\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"\\nüéâ Evaluation completed for {len(evaluation_results)} models!\")\n",
    "        return evaluation_results\n",
    "\n",
    "    def generate_comparison_report(self) -> pd.DataFrame:\n",
    "        \"\"\"Generate a comprehensive comparison report\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"‚ùå No evaluation results available\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Create comparison dataframe\n",
    "        comparison_data = []\n",
    "\n",
    "        for model_name, result in self.results.items():\n",
    "            row = {\n",
    "                'Model': model_name,\n",
    "                'Accuracy': result['accuracy'],\n",
    "                'F1-Macro': result['f1_macro'],\n",
    "                'F1-Weighted': result['f1_weighted'],\n",
    "                'Precision': result['precision_macro'],\n",
    "                'Recall': result['recall_macro'],\n",
    "                'Training Time (s)': result.get('training_time', 0),\n",
    "                'Inference Time (ms)': result['avg_inference_time'] * 1000,\n",
    "                'Model Size (M)': result.get('model_size', 0) / 1e6,\n",
    "                'Samples': result['samples_evaluated']\n",
    "            }\n",
    "            comparison_data.append(row)\n",
    "\n",
    "        df = pd.DataFrame(comparison_data)\n",
    "\n",
    "        # Sort by F1-Macro score (descending)\n",
    "        df = df.sort_values('F1-Macro', ascending=False).reset_index(drop=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_best_models(self, metric='f1_macro', top_k=3):\n",
    "        \"\"\"Get top-k best performing models\"\"\"\n",
    "        if not self.results:\n",
    "            return []\n",
    "\n",
    "        # Sort models by specified metric\n",
    "        sorted_models = sorted(\n",
    "            self.results.items(),\n",
    "            key=lambda x: x[1][metric],\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "        return sorted_models[:top_k]\n",
    "\n",
    "    def save_results(self, filename='evaluation_results.json'):\n",
    "        \"\"\"Save evaluation results to file\"\"\"\n",
    "        save_results(self.results, filename)\n",
    "\n",
    "    def load_results(self, filename='evaluation_results.json'):\n",
    "        \"\"\"Load evaluation results from file\"\"\"\n",
    "        self.results = load_results(filename)\n",
    "        return self.results\n",
    "\n",
    "print(\"‚úÖ EvaluationManager class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdfyROIRgpuj"
   },
   "source": [
    "### 7.1 Initialize Evaluation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà EvaluationManager initialized with 6 emotion classes\n",
      "üìä Evaluation system ready\n",
      "   Emotion classes: ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n",
      "   Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Initialize evaluation manager\n",
    "evaluator = EvaluationManager(emotion_labels=config.emotion_labels)\n",
    "\n",
    "print(f\"üìä Evaluation system ready\")\n",
    "print(f\"   Emotion classes: {evaluator.emotion_labels}\")\n",
    "print(f\"   Device: {evaluator.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWemet-Fgpuj"
   },
   "source": [
    "## 8. Advanced Visualization System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ VisualizationEngine class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class VisualizationEngine:\n",
    "    \"\"\"Professional-grade visualization system for model comparison\"\"\"\n",
    "\n",
    "    def __init__(self, emotion_labels=None, color_palette='viridis'):\n",
    "        self.emotion_labels = emotion_labels or [\"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"]\n",
    "        self.color_palette = color_palette\n",
    "        self.colors = px.colors.qualitative.Set3\n",
    "\n",
    "        # Professional color scheme\n",
    "        self.model_colors = {\n",
    "            'bilstm-attention': '#1f77b4',\n",
    "            'cnn': '#ff7f0e',\n",
    "            'roberta-base': '#2ca02c',\n",
    "            'roberta-large': '#d62728',\n",
    "            'deberta-v3-base': '#9467bd',\n",
    "            'distilbert-base': '#8c564b',\n",
    "            'electra-base': '#e377c2',\n",
    "            'xlnet-base': '#7f7f7f',\n",
    "            'albert-base': '#bcbd22'\n",
    "        }\n",
    "\n",
    "        print(f\"üé® VisualizationEngine initialized with {len(self.emotion_labels)} emotion classes\")\n",
    "\n",
    "    def plot_performance_comparison(self, results: Dict, metrics=['accuracy', 'f1_macro', 'f1_weighted']):\n",
    "        \"\"\"Create interactive performance comparison chart\"\"\"\n",
    "        if not results:\n",
    "            print(\"‚ùå No results available for visualization\")\n",
    "            return None\n",
    "\n",
    "        # Prepare data\n",
    "        models = list(results.keys())\n",
    "\n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=len(metrics),\n",
    "            subplot_titles=[metric.replace('_', ' ').title() for metric in metrics],\n",
    "            specs=[[{'secondary_y': False} for _ in metrics]]\n",
    "        )\n",
    "\n",
    "        for i, metric in enumerate(metrics, 1):\n",
    "            values = [results[model][metric] for model in models]\n",
    "            colors = [self.model_colors.get(model, '#636EFA') for model in models]\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=models,\n",
    "                    y=values,\n",
    "                    name=metric.replace('_', ' ').title(),\n",
    "                    marker_color=colors,\n",
    "                    text=[f'{v:.3f}' for v in values],\n",
    "                    textposition='auto',\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=1, col=i\n",
    "            )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title={\n",
    "                'text': 'Model Performance Comparison',\n",
    "                'x': 0.5,\n",
    "                'xanchor': 'center',\n",
    "                'font': {'size': 20}\n",
    "            },\n",
    "            height=500,\n",
    "            showlegend=False,\n",
    "            template='plotly_white'\n",
    "        )\n",
    "\n",
    "        # Update x-axis labels\n",
    "        for i in range(1, len(metrics) + 1):\n",
    "            fig.update_xaxes(tickangle=45, row=1, col=i)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def plot_confusion_matrices(self, results: Dict, models_to_show=None):\n",
    "        \"\"\"Create confusion matrix heatmaps for multiple models\"\"\"\n",
    "        if not results:\n",
    "            return None\n",
    "\n",
    "        models = models_to_show or list(results.keys())\n",
    "        n_models = len(models)\n",
    "\n",
    "        # Calculate grid dimensions\n",
    "        cols = min(3, n_models)\n",
    "        rows = (n_models + cols - 1) // cols\n",
    "\n",
    "        fig = make_subplots(\n",
    "            rows=rows, cols=cols,\n",
    "            subplot_titles=[f'{model.upper()}' for model in models],\n",
    "            specs=[[{'type': 'heatmap'} for _ in range(cols)] for _ in range(rows)]\n",
    "        )\n",
    "\n",
    "        for idx, model in enumerate(models):\n",
    "            if model not in results:\n",
    "                continue\n",
    "\n",
    "            row = idx // cols + 1\n",
    "            col = idx % cols + 1\n",
    "\n",
    "            cm = np.array(results[model]['confusion_matrix'])\n",
    "\n",
    "            # Normalize confusion matrix\n",
    "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "            # Create annotations\n",
    "            annotations = []\n",
    "            for i in range(len(self.emotion_labels)):\n",
    "                for j in range(len(self.emotion_labels)):\n",
    "                    annotations.append(\n",
    "                        dict(\n",
    "                            x=j, y=i,\n",
    "                            text=str(cm[i][j]),\n",
    "                            showarrow=False,\n",
    "                            font=dict(color='white' if cm_normalized[i][j] > 0.5 else 'black')\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Heatmap(\n",
    "                    z=cm_normalized,\n",
    "                    x=self.emotion_labels,\n",
    "                    y=self.emotion_labels,\n",
    "                    colorscale='Blues',\n",
    "                    showscale=idx == 0,  # Show scale only for first plot\n",
    "                    text=cm,\n",
    "                    texttemplate='%{text}',\n",
    "                    textfont={'color': 'white'},\n",
    "                    hovertemplate='Predicted: %{x}<br>Actual: %{y}<br>Count: %{text}<br>Rate: %{z:.2f}<extra></extra>'\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title={\n",
    "                'text': 'Confusion Matrices Comparison',\n",
    "                'x': 0.5,\n",
    "                'xanchor': 'center',\n",
    "                'font': {'size': 20}\n",
    "            },\n",
    "            height=200 * rows + 100,\n",
    "            template='plotly_white'\n",
    "        )\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def plot_training_curves(self, training_history: Dict):\n",
    "        \"\"\"Plot training curves for multiple models\"\"\"\n",
    "        if not training_history:\n",
    "            return None\n",
    "\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            subplot_titles=['Training Loss', 'Validation Loss', 'Validation Accuracy', 'Validation F1-Score'],\n",
    "            specs=[[{'secondary_y': False}, {'secondary_y': False}],\n",
    "                   [{'secondary_y': False}, {'secondary_y': False}]]\n",
    "        )\n",
    "\n",
    "        metrics = [\n",
    "            ('train_loss', 1, 1),\n",
    "            ('val_loss', 1, 2),\n",
    "            ('val_accuracy', 2, 1),\n",
    "            ('val_f1', 2, 2)\n",
    "        ]\n",
    "\n",
    "        for model_name, history in training_history.items():\n",
    "            color = self.model_colors.get(model_name, '#636EFA')\n",
    "\n",
    "            for metric, row, col in metrics:\n",
    "                if metric in history:\n",
    "                    epochs = list(range(1, len(history[metric]) + 1))\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=epochs,\n",
    "                            y=history[metric],\n",
    "                            mode='lines+markers',\n",
    "                            name=f'{model_name}',\n",
    "                            line=dict(color=color),\n",
    "                            showlegend=(row == 1 and col == 1)  # Show legend only once\n",
    "                        ),\n",
    "                        row=row, col=col\n",
    "                    )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title={\n",
    "                'text': 'Training Progress Comparison',\n",
    "                'x': 0.5,\n",
    "                'xanchor': 'center',\n",
    "                'font': {'size': 20}\n",
    "            },\n",
    "            height=600,\n",
    "            template='plotly_white'\n",
    "        )\n",
    "\n",
    "        # Update axis labels\n",
    "        fig.update_xaxes(title_text='Epoch')\n",
    "        fig.update_yaxes(title_text='Loss', row=1, col=1)\n",
    "        fig.update_yaxes(title_text='Loss', row=1, col=2)\n",
    "        fig.update_yaxes(title_text='Accuracy', row=2, col=1)\n",
    "        fig.update_yaxes(title_text='F1-Score', row=2, col=2)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def plot_radar_chart(self, results: Dict, models_to_show=None):\n",
    "        \"\"\"Create radar chart for per-emotion performance\"\"\"\n",
    "        if not results:\n",
    "            return None\n",
    "\n",
    "        models = models_to_show or list(results.keys())\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        for model in models:\n",
    "            if model not in results:\n",
    "                continue\n",
    "\n",
    "            f1_scores = results[model]['f1_per_class']\n",
    "            color = self.model_colors.get(model, '#636EFA')\n",
    "\n",
    "            fig.add_trace(go.Scatterpolar(\n",
    "                r=f1_scores + [f1_scores[0]],  # Close the polygon\n",
    "                theta=self.emotion_labels + [self.emotion_labels[0]],\n",
    "                fill='toself',\n",
    "                name=model.upper(),\n",
    "                line_color=color,\n",
    "                fillcolor=color,\n",
    "                opacity=0.3\n",
    "            ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            polar=dict(\n",
    "                radialaxis=dict(\n",
    "                    visible=True,\n",
    "                    range=[0, 1]\n",
    "                )\n",
    "            ),\n",
    "            title={\n",
    "                'text': 'Per-Emotion F1-Score Comparison',\n",
    "                'x': 0.5,\n",
    "                'xanchor': 'center',\n",
    "                'font': {'size': 20}\n",
    "            },\n",
    "            height=600,\n",
    "            template='plotly_white'\n",
    "        )\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def plot_efficiency_analysis(self, results: Dict):\n",
    "        \"\"\"Create efficiency analysis plots\"\"\"\n",
    "        if not results:\n",
    "            return None\n",
    "\n",
    "        # Prepare data\n",
    "        models = []\n",
    "        f1_scores = []\n",
    "        training_times = []\n",
    "        inference_times = []\n",
    "        model_sizes = []\n",
    "\n",
    "        for model, result in results.items():\n",
    "            models.append(model)\n",
    "            f1_scores.append(result['f1_macro'])\n",
    "            training_times.append(result.get('training_time', 0))\n",
    "            inference_times.append(result['avg_inference_time'] * 1000)  # Convert to ms\n",
    "            model_sizes.append(result.get('model_size', 0) / 1e6)  # Convert to millions\n",
    "\n",
    "        fig = make_subplots(\n",
    "            rows=1, cols=2,\n",
    "            subplot_titles=['Training Time vs Performance', 'Model Size vs Performance'],\n",
    "            specs=[[{'secondary_y': False}, {'secondary_y': False}]]\n",
    "        )\n",
    "\n",
    "        # Training time vs performance\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=training_times,\n",
    "                y=f1_scores,\n",
    "                mode='markers+text',\n",
    "                text=models,\n",
    "                textposition='top center',\n",
    "                marker=dict(\n",
    "                    size=10,\n",
    "                    color=[self.model_colors.get(m, '#636EFA') for m in models]\n",
    "                ),\n",
    "                name='Models',\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "        # Model size vs performance\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=model_sizes,\n",
    "                y=f1_scores,\n",
    "                mode='markers+text',\n",
    "                text=models,\n",
    "                textposition='top center',\n",
    "                marker=dict(\n",
    "                    size=10,\n",
    "                    color=[self.model_colors.get(m, '#636EFA') for m in models]\n",
    "                ),\n",
    "                name='Models',\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title={\n",
    "                'text': 'Model Efficiency Analysis',\n",
    "                'x': 0.5,\n",
    "                'xanchor': 'center',\n",
    "                'font': {'size': 20}\n",
    "            },\n",
    "            height=500,\n",
    "            template='plotly_white'\n",
    "        )\n",
    "\n",
    "        # Update axis labels\n",
    "        fig.update_xaxes(title_text='Training Time (seconds)', row=1, col=1)\n",
    "        fig.update_xaxes(title_text='Model Size (M parameters)', row=1, col=2)\n",
    "        fig.update_yaxes(title_text='F1-Macro Score', row=1, col=1)\n",
    "        fig.update_yaxes(title_text='F1-Macro Score', row=1, col=2)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def create_model_ranking(self, results: Dict, metric='f1_macro'):\n",
    "        \"\"\"Create model performance ranking\"\"\"\n",
    "        if not results:\n",
    "            return None\n",
    "\n",
    "        # Sort models by metric\n",
    "        sorted_models = sorted(\n",
    "            results.items(),\n",
    "            key=lambda x: x[1][metric],\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "        models = [item[0] for item in sorted_models]\n",
    "        scores = [item[1][metric] for item in sorted_models]\n",
    "        colors = [self.model_colors.get(model, '#636EFA') for model in models]\n",
    "\n",
    "        fig = go.Figure(data=[\n",
    "            go.Bar(\n",
    "                y=models,\n",
    "                x=scores,\n",
    "                orientation='h',\n",
    "                marker_color=colors,\n",
    "                text=[f'{score:.3f}' for score in scores],\n",
    "                textposition='auto'\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        fig.update_layout(\n",
    "            title={\n",
    "                'text': f'Model Ranking by {metric.replace(\"_\", \" \").title()}',\n",
    "                'x': 0.5,\n",
    "                'xanchor': 'center',\n",
    "                'font': {'size': 20}\n",
    "            },\n",
    "            xaxis_title=metric.replace('_', ' ').title(),\n",
    "            yaxis_title='Models',\n",
    "            height=400,\n",
    "            template='plotly_white'\n",
    "        )\n",
    "\n",
    "        return fig\n",
    "\n",
    "    def save_figure(self, fig, filename, format='html'):\n",
    "        \"\"\"Save figure to file\"\"\"\n",
    "        if fig is None:\n",
    "            print(\"‚ùå No figure to save\")\n",
    "            return\n",
    "\n",
    "        filepath = os.path.join('visualizations', filename)\n",
    "\n",
    "        if format == 'html':\n",
    "            fig.write_html(filepath)\n",
    "        elif format == 'png':\n",
    "            fig.write_image(filepath, width=1200, height=800)\n",
    "        elif format == 'pdf':\n",
    "            fig.write_image(filepath, width=1200, height=800)\n",
    "\n",
    "        print(f\"üíæ Figure saved to {filepath}\")\n",
    "\n",
    "print(\"‚úÖ VisualizationEngine class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMZfKhvygpuj"
   },
   "source": [
    "### 8.1 Initialize Visualization System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® VisualizationEngine initialized with 6 emotion classes\n",
      "üé® Visualization system ready\n",
      "   Color palette: viridis\n",
      "   Available model colors: 9\n"
     ]
    }
   ],
   "source": [
    "# Initialize visualization engine\n",
    "visualizer = VisualizationEngine(emotion_labels=config.emotion_labels)\n",
    "\n",
    "print(f\"üé® Visualization system ready\")\n",
    "print(f\"   Color palette: {visualizer.color_palette}\")\n",
    "print(f\"   Available model colors: {len(visualizer.model_colors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-Dns_B1gpuj"
   },
   "source": [
    "## 9. Main Execution Pipeline\n",
    "\n",
    "This section orchestrates the entire model comparison process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JXXCFmXgpuj"
   },
   "source": [
    "### 9.1 Quick Test Run (Small Scale)\n",
    "\n",
    "Let's first run a quick test with a subset of models to ensure everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Quick Test Configuration:\n",
      "   Models: ['bilstm-attention', 'cnn', 'roberta-base', 'distilbert-base', 'electra-base', 'albert-base']\n",
      "   Epochs: 1\n",
      "   Batch size: 32\n",
      "   Max samples: 1000\n"
     ]
    }
   ],
   "source": [
    "# Quick test configuration\n",
    "TEST_CONFIG = {\n",
    "    'models': ['bilstm-attention', 'cnn', 'roberta-base', 'distilbert-base', 'electra-base', 'albert-base'],  # Start with traditional models\n",
    "    'epochs': 1,  # Quick training\n",
    "    'batch_size': 32,\n",
    "    'max_samples': 1000  # Limit dataset size for testing\n",
    "}\n",
    "\n",
    "print(\"üß™ Quick Test Configuration:\")\n",
    "print(f\"   Models: {TEST_CONFIG['models']}\")\n",
    "print(f\"   Epochs: {TEST_CONFIG['epochs']}\")\n",
    "print(f\"   Batch size: {TEST_CONFIG['batch_size']}\")\n",
    "print(f\"   Max samples: {TEST_CONFIG['max_samples']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting quick test run...\n",
      "\n",
      "üìö Training models...\n",
      "üöÄ Starting batch training for 6 models...\n",
      "\n",
      "============================================================\n",
      "Training Model 1/6: BILSTM-ATTENTION\n",
      "============================================================\n",
      "\n",
      "üéØ Starting training for bilstm-attention...\n",
      "‚úÖ Data loaders created for traditional models\n",
      "üèãÔ∏è Training BiLSTM-Attention for 1 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22391f71d3714d6aa102f81d7cdb4efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1 [Train]:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.6719, Val Loss: 1.0990, Val Acc: 0.5195, Val F1: 0.5389\n",
      "üíæ Model saved to models/bilstm_attention_best.pt\n",
      "‚úÖ Training completed in 18.7s\n",
      "‚úÖ bilstm-attention training completed successfully!\n",
      "\n",
      "============================================================\n",
      "Training Model 2/6: CNN\n",
      "============================================================\n",
      "\n",
      "üéØ Starting training for cnn...\n",
      "‚úÖ Data loaders created for traditional models\n",
      "üèãÔ∏è Training CNN-Emotion for 1 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ba4a72894a43249b2d69cfaa2434cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1 [Train]:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.7433, Val Loss: 1.3656, Val Acc: 0.4300, Val F1: 0.4443\n",
      "üíæ Model saved to models/cnn_emotion_best.pt\n",
      "‚úÖ Training completed in 8.0s\n",
      "‚úÖ cnn training completed successfully!\n",
      "\n",
      "============================================================\n",
      "Training Model 3/6: ROBERTA-BASE\n",
      "============================================================\n",
      "\n",
      "üéØ Starting training for roberta-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded transformer model: roberta-base\n",
      "‚úÖ Data loaders created for roberta-base models\n",
      "ü§ñ Training ROBERTA-BASE for 1 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab51509ff7124af2923a76e2b1691dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1 [Train]:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.6903, Val Loss: 0.2719, Val Acc: 0.9015, Val F1: 0.8720\n",
      "üíæ Model saved to models/roberta_base_best.pt\n",
      "‚úÖ Training completed in 4.5m\n",
      "‚úÖ roberta-base training completed successfully!\n",
      "\n",
      "============================================================\n",
      "Training Model 4/6: DISTILBERT-BASE\n",
      "============================================================\n",
      "\n",
      "üéØ Starting training for distilbert-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded transformer model: distilbert-base-uncased\n",
      "‚úÖ Data loaders created for distilbert-base models\n",
      "ü§ñ Training DISTILBERT-BASE for 1 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2ad2fee73e4911a73ccca055d19562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1 [Train]:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.7141, Val Loss: 0.2969, Val Acc: 0.9120, Val F1: 0.8684\n",
      "üíæ Model saved to models/distilbert_base_best.pt\n",
      "‚úÖ Training completed in 2.3m\n",
      "‚úÖ distilbert-base training completed successfully!\n",
      "\n",
      "============================================================\n",
      "Training Model 5/6: ELECTRA-BASE\n",
      "============================================================\n",
      "\n",
      "üéØ Starting training for electra-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded transformer model: google/electra-base-discriminator\n",
      "‚úÖ Data loaders created for electra-base models\n",
      "ü§ñ Training ELECTRA-BASE for 1 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad1d1ee5ad3478a8f95bdd3cf0588db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1 [Train]:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.0490, Val Loss: 0.6230, Val Acc: 0.8105, Val F1: 0.6853\n",
      "üíæ Model saved to models/electra_base_best.pt\n",
      "‚úÖ Training completed in 4.7m\n",
      "‚úÖ electra-base training completed successfully!\n",
      "\n",
      "============================================================\n",
      "Training Model 6/6: ALBERT-BASE\n",
      "============================================================\n",
      "\n",
      "üéØ Starting training for albert-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded transformer model: albert-base-v2\n",
      "‚úÖ Data loaders created for albert-base models\n",
      "ü§ñ Training ALBERT-BASE for 1 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fbdeb6ef3b4a9b8131946b3825a495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/1 [Train]:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.7630, Val Loss: 0.3412, Val Acc: 0.9015, Val F1: 0.8689\n",
      "üíæ Model saved to models/albert_base_best.pt\n",
      "‚úÖ Training completed in 5.0m\n",
      "‚úÖ albert-base training completed successfully!\n",
      "\n",
      "üéâ Batch training completed!\n",
      "   Successful models: 6/6\n",
      "   Total time: 17.1m\n",
      "\n",
      "üìä Evaluating models...\n",
      "üéØ Starting comprehensive evaluation of 6 models...\n",
      "‚úÖ Data loaders created for traditional models\n",
      "\n",
      "üìä Evaluating bilstm-attention...\n",
      "üîç Evaluating bilstm-attention on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1274ca26a84817b3fec3732f08f3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ bilstm-attention Evaluation Results:\n",
      "   Accuracy: 0.5110\n",
      "   F1-Macro: 0.5121\n",
      "   F1-Weighted: 0.5161\n",
      "   Avg Inference Time: 8.74ms per batch\n",
      "‚úÖ Data loaders created for traditional models\n",
      "\n",
      "üìä Evaluating cnn...\n",
      "üîç Evaluating cnn on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95182b38028447e3983d966865796b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ cnn Evaluation Results:\n",
      "   Accuracy: 0.4005\n",
      "   F1-Macro: 0.4081\n",
      "   F1-Weighted: 0.3899\n",
      "   Avg Inference Time: 1.97ms per batch\n",
      "‚úÖ Data loaders created for roberta-base models\n",
      "\n",
      "üìä Evaluating roberta-base...\n",
      "ü§ñ Evaluating roberta-base on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb0cc7715744b208d85c1c1d1a68fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ roberta-base Evaluation Results:\n",
      "   Accuracy: 0.9045\n",
      "   F1-Macro: 0.8585\n",
      "   F1-Weighted: 0.9053\n",
      "   Avg Inference Time: 15.51ms per batch\n",
      "‚úÖ Data loaders created for distilbert-base models\n",
      "\n",
      "üìä Evaluating distilbert-base...\n",
      "ü§ñ Evaluating distilbert-base on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50efd8fb8d5444a8aff5fc7d4161bfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ distilbert-base Evaluation Results:\n",
      "   Accuracy: 0.9070\n",
      "   F1-Macro: 0.8550\n",
      "   F1-Weighted: 0.9053\n",
      "   Avg Inference Time: 8.36ms per batch\n",
      "‚úÖ Data loaders created for electra-base models\n",
      "\n",
      "üìä Evaluating electra-base...\n",
      "ü§ñ Evaluating electra-base on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cb82d2572a4bd8a31156d87e89e0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ electra-base Evaluation Results:\n",
      "   Accuracy: 0.8370\n",
      "   F1-Macro: 0.6970\n",
      "   F1-Weighted: 0.8176\n",
      "   Avg Inference Time: 18.92ms per batch\n",
      "‚úÖ Data loaders created for albert-base models\n",
      "\n",
      "üìä Evaluating albert-base...\n",
      "ü§ñ Evaluating albert-base on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8aeb9fb5da54d0785d8f4a1dc3e65a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ albert-base Evaluation Results:\n",
      "   Accuracy: 0.8935\n",
      "   F1-Macro: 0.8420\n",
      "   F1-Weighted: 0.8926\n",
      "   Avg Inference Time: 18.22ms per batch\n",
      "\n",
      "üéâ Evaluation completed for 6 models!\n",
      "\n",
      "üìã Generating comparison report...\n",
      "\n",
      "üèÜ Model Comparison Results:\n",
      "           Model  Accuracy  F1-Macro  F1-Weighted  Precision  Recall  Training Time (s)  Inference Time (ms)  Model Size (M)  Samples\n",
      "    roberta-base    0.9045    0.8585       0.9053     0.8513  0.8678           267.4825              15.5066        124.6502     2000\n",
      " distilbert-base    0.9070    0.8550       0.9053     0.8829  0.8373           138.2077               8.3564         66.9581     2000\n",
      "     albert-base    0.8935    0.8420       0.8926     0.8515  0.8334           298.5468              18.2246         11.6882     2000\n",
      "    electra-base    0.8370    0.6970       0.8176     0.8318  0.6703           280.3746              18.9182        109.4869     2000\n",
      "bilstm-attention    0.5110    0.5121       0.5161     0.4976  0.5843            18.6845               8.7380          3.1567     2000\n",
      "             cnn    0.4005    0.4081       0.3899     0.4412  0.4933             7.9622               1.9720          0.9344     2000\n",
      "\n",
      "üé® Creating visualizations...\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "#1f77b4",
           "#ff7f0e",
           "#2ca02c",
           "#8c564b",
           "#e377c2",
           "#bcbd22"
          ]
         },
         "name": "Accuracy",
         "showlegend": false,
         "text": [
          "0.511",
          "0.401",
          "0.904",
          "0.907",
          "0.837",
          "0.893"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "bilstm-attention",
          "cnn",
          "roberta-base",
          "distilbert-base",
          "electra-base",
          "albert-base"
         ],
         "xaxis": "x",
         "y": [
          0.511,
          0.4005,
          0.9045,
          0.907,
          0.837,
          0.8935
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": [
           "#1f77b4",
           "#ff7f0e",
           "#2ca02c",
           "#8c564b",
           "#e377c2",
           "#bcbd22"
          ]
         },
         "name": "F1 Macro",
         "showlegend": false,
         "text": [
          "0.512",
          "0.408",
          "0.859",
          "0.855",
          "0.697",
          "0.842"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "bilstm-attention",
          "cnn",
          "roberta-base",
          "distilbert-base",
          "electra-base",
          "albert-base"
         ],
         "xaxis": "x2",
         "y": [
          0.5120823383853288,
          0.40813352502562056,
          0.8585161905816268,
          0.8549873267333599,
          0.696972025602853,
          0.8419778664528144
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": [
           "#1f77b4",
           "#ff7f0e",
           "#2ca02c",
           "#8c564b",
           "#e377c2",
           "#bcbd22"
          ]
         },
         "name": "F1 Weighted",
         "showlegend": false,
         "text": [
          "0.516",
          "0.390",
          "0.905",
          "0.905",
          "0.818",
          "0.893"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "bilstm-attention",
          "cnn",
          "roberta-base",
          "distilbert-base",
          "electra-base",
          "albert-base"
         ],
         "xaxis": "x3",
         "y": [
          0.5161141855328012,
          0.3899442499309653,
          0.905278230436718,
          0.905328837801099,
          0.817644730531632,
          0.8926090436091607
         ],
         "yaxis": "y3"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Accuracy",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "F1 Macro",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "F1 Weighted",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 500,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 20
         },
         "text": "Model Performance Comparison",
         "x": 0.5,
         "xanchor": "center"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.2888888888888889
         ],
         "tickangle": 45
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.35555555555555557,
          0.6444444444444445
         ],
         "tickangle": 45
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.7111111111111111,
          1
         ],
         "tickangle": 45
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ]
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Figure saved to visualizations/quick_test_performance.html\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "#1f77b4"
         },
         "mode": "lines+markers",
         "name": "bilstm-attention",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x",
         "y": [
          1.6718763469457627
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "#1f77b4"
         },
         "mode": "lines+markers",
         "name": "bilstm-attention",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x2",
         "y": [
          1.098971652606177
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "#1f77b4"
         },
         "mode": "lines+markers",
         "name": "bilstm-attention",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x3",
         "y": [
          0.5195
         ],
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "#1f77b4"
         },
         "mode": "lines+markers",
         "name": "bilstm-attention",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x4",
         "y": [
          0.5388704437316515
         ],
         "yaxis": "y4"
        },
        {
         "line": {
          "color": "#ff7f0e"
         },
         "mode": "lines+markers",
         "name": "cnn",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x",
         "y": [
          1.7433127536773683
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "#ff7f0e"
         },
         "mode": "lines+markers",
         "name": "cnn",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x2",
         "y": [
          1.3656178703383794
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "#ff7f0e"
         },
         "mode": "lines+markers",
         "name": "cnn",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x3",
         "y": [
          0.43
         ],
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "#ff7f0e"
         },
         "mode": "lines+markers",
         "name": "cnn",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x4",
         "y": [
          0.4443096679648946
         ],
         "yaxis": "y4"
        },
        {
         "line": {
          "color": "#2ca02c"
         },
         "mode": "lines+markers",
         "name": "roberta-base",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x",
         "y": [
          0.6903257331103086
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "#2ca02c"
         },
         "mode": "lines+markers",
         "name": "roberta-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x2",
         "y": [
          0.2719442176203879
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "#2ca02c"
         },
         "mode": "lines+markers",
         "name": "roberta-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x3",
         "y": [
          0.9015
         ],
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "#2ca02c"
         },
         "mode": "lines+markers",
         "name": "roberta-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x4",
         "y": [
          0.8719583438259799
         ],
         "yaxis": "y4"
        },
        {
         "line": {
          "color": "#8c564b"
         },
         "mode": "lines+markers",
         "name": "distilbert-base",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x",
         "y": [
          0.7141153095960617
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "#8c564b"
         },
         "mode": "lines+markers",
         "name": "distilbert-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x2",
         "y": [
          0.2968990667944863
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "#8c564b"
         },
         "mode": "lines+markers",
         "name": "distilbert-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x3",
         "y": [
          0.912
         ],
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "#8c564b"
         },
         "mode": "lines+markers",
         "name": "distilbert-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x4",
         "y": [
          0.868441122540825
         ],
         "yaxis": "y4"
        },
        {
         "line": {
          "color": "#e377c2"
         },
         "mode": "lines+markers",
         "name": "electra-base",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x",
         "y": [
          1.0490293592214583
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "#e377c2"
         },
         "mode": "lines+markers",
         "name": "electra-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x2",
         "y": [
          0.6229997948994712
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "#e377c2"
         },
         "mode": "lines+markers",
         "name": "electra-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x3",
         "y": [
          0.8105
         ],
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "#e377c2"
         },
         "mode": "lines+markers",
         "name": "electra-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x4",
         "y": [
          0.6852533636872341
         ],
         "yaxis": "y4"
        },
        {
         "line": {
          "color": "#bcbd22"
         },
         "mode": "lines+markers",
         "name": "albert-base",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x",
         "y": [
          0.762993872821331
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "#bcbd22"
         },
         "mode": "lines+markers",
         "name": "albert-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x2",
         "y": [
          0.3412263147414677
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "#bcbd22"
         },
         "mode": "lines+markers",
         "name": "albert-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x3",
         "y": [
          0.9015
         ],
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "#bcbd22"
         },
         "mode": "lines+markers",
         "name": "albert-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1
         ],
         "xaxis": "x4",
         "y": [
          0.8688808355720931
         ],
         "yaxis": "y4"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Training Loss",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Validation Loss",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Validation Accuracy",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Validation F1-Score",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 600,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 20
         },
         "text": "Training Progress Comparison",
         "x": 0.5,
         "xanchor": "center"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ],
         "title": {
          "text": "Loss"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.625,
          1
         ],
         "title": {
          "text": "Loss"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.375
         ],
         "title": {
          "text": "Accuracy"
         }
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.375
         ],
         "title": {
          "text": "F1-Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Figure saved to visualizations/quick_test_training_curves.html\n",
      "üíæ Results saved to results/quick_test_results.json\n",
      "\n",
      "‚úÖ Quick test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "def run_quick_test():\n",
    "    \"\"\"Run a quick test with traditional models\"\"\"\n",
    "    print(\"üöÄ Starting quick test run...\")\n",
    "\n",
    "    # Check if data is ready\n",
    "    if data_manager.dataset is None:\n",
    "        print(\"‚ùå Dataset not loaded. Please run data loading cells first.\")\n",
    "        return\n",
    "\n",
    "    # FIX: Build vocabulary if not already built\n",
    "    if data_manager.vocab is None:\n",
    "        print(\"üî§ Building vocabulary for traditional models...\")\n",
    "        # Get all text data for vocabulary building - FIX: Convert to list properly\n",
    "        all_texts = []\n",
    "        all_texts.extend(list(data_manager.dataset['train']['text']))\n",
    "        all_texts.extend(list(data_manager.dataset['validation']['text']))\n",
    "        all_texts.extend(list(data_manager.dataset['test']['text']))\n",
    "\n",
    "        data_manager.build_vocab(all_texts)\n",
    "        print(f\"‚úÖ Vocabulary built with {len(data_manager.vocab)} words\")\n",
    "\n",
    "    # Train models\n",
    "    print(\"\\nüìö Training models...\")\n",
    "    training_results = trainer.train_multiple_models(\n",
    "        TEST_CONFIG['models'],\n",
    "        data_manager,\n",
    "        epochs=TEST_CONFIG['epochs'],\n",
    "        batch_size=TEST_CONFIG['batch_size']\n",
    "    )\n",
    "\n",
    "    # Evaluate models\n",
    "    print(\"\\nüìä Evaluating models...\")\n",
    "    evaluation_results = evaluator.evaluate_all_models(\n",
    "        training_results,\n",
    "        data_manager,\n",
    "        batch_size=TEST_CONFIG['batch_size']\n",
    "    )\n",
    "\n",
    "    # Generate comparison report\n",
    "    if evaluation_results:\n",
    "        print(\"\\nüìã Generating comparison report...\")\n",
    "        comparison_df = evaluator.generate_comparison_report()\n",
    "        print(\"\\nüèÜ Model Comparison Results:\")\n",
    "        print(comparison_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "        # Create basic visualizations\n",
    "        print(\"\\nüé® Creating visualizations...\")\n",
    "\n",
    "        # Performance comparison\n",
    "        perf_fig = visualizer.plot_performance_comparison(evaluation_results)\n",
    "        if perf_fig:\n",
    "            perf_fig.show()\n",
    "            visualizer.save_figure(perf_fig, 'quick_test_performance.html')\n",
    "\n",
    "        # Training curves\n",
    "        training_history = {name: result['history'] for name, result in training_results.items()\n",
    "                          if result['status'] == 'success'}\n",
    "        if training_history:\n",
    "            curves_fig = visualizer.plot_training_curves(training_history)\n",
    "            if curves_fig:\n",
    "                curves_fig.show()\n",
    "                visualizer.save_figure(curves_fig, 'quick_test_training_curves.html')\n",
    "\n",
    "        # Save results\n",
    "        evaluator.save_results('quick_test_results.json')\n",
    "\n",
    "        print(\"\\n‚úÖ Quick test completed successfully!\")\n",
    "        return evaluation_results\n",
    "\n",
    "    else:\n",
    "        print(\"‚ùå No successful evaluations to report\")\n",
    "        return None\n",
    "\n",
    "# Run the quick test\n",
    "quick_results = run_quick_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBMn8GxBgpuo"
   },
   "source": [
    "### 9.2 Full Model Comparison Pipeline\n",
    "\n",
    "Now let's run the complete comparison with all available models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Full Comparison Configuration:\n",
      "   Traditional models: ['bilstm-attention', 'cnn']\n",
      "   Available transformer models: ['roberta-base', 'distilbert-base', 'electra-base', 'albert-base']\n",
      "   Total models: 6\n",
      "   Epochs: 3\n",
      "   Batch size: 16\n",
      "   Run full comparison: True\n"
     ]
    }
   ],
   "source": [
    "# Full comparison configuration\n",
    "FULL_CONFIG = {\n",
    "    'traditional_models': ['bilstm-attention', 'cnn'],\n",
    "    'transformer_models': ['roberta-base', 'distilbert-base', 'electra-base', 'albert-base'],\n",
    "    #'transformer_models': ['roberta-base', 'distilbert-base'],\n",
    "    'epochs': 3,\n",
    "    'batch_size': 16,\n",
    "    'run_full_comparison': True  # Set to True to run full comparison\n",
    "}\n",
    "\n",
    "# Only include models that have tokenizers registered\n",
    "available_transformers = [model for model in FULL_CONFIG['transformer_models']\n",
    "                         if model in data_manager.tokenizers]\n",
    "\n",
    "all_models = FULL_CONFIG['traditional_models'] + available_transformers\n",
    "\n",
    "print(\"üéØ Full Comparison Configuration:\")\n",
    "print(f\"   Traditional models: {FULL_CONFIG['traditional_models']}\")\n",
    "print(f\"   Available transformer models: {available_transformers}\")\n",
    "print(f\"   Total models: {len(all_models)}\")\n",
    "print(f\"   Epochs: {FULL_CONFIG['epochs']}\")\n",
    "print(f\"   Batch size: {FULL_CONFIG['batch_size']}\")\n",
    "print(f\"   Run full comparison: {FULL_CONFIG['run_full_comparison']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting full model comparison with 6 models...\n",
      "   This may take a while depending on your hardware.\n",
      "\n",
      "================================================================================\n",
      "üèãÔ∏è TRAINING PHASE\n",
      "================================================================================\n",
      "üöÄ Starting batch training for 6 models...\n",
      "\n",
      "============================================================\n",
      "Training Model 1/6: BILSTM-ATTENTION\n",
      "============================================================\n",
      "\n",
      "üéØ Starting training for bilstm-attention...\n",
      "‚úÖ Data loaders created for traditional models\n",
      "üèãÔ∏è Training BiLSTM-Attention for 3 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c245d528a442458199d6716931739a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.5707, Val Loss: 0.8625, Val Acc: 0.6250, Val F1: 0.6360\n",
      "üíæ Model saved to models/bilstm_attention_best.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2459ae4c43504be0a05d9a64637a4455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.8874, Val Loss: 0.4114, Val Acc: 0.8470, Val F1: 0.8295\n",
      "üíæ Model saved to models/bilstm_attention_best.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c292602f2b4e3cbdee3d79e0a6597e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.5700, Val Loss: 0.2430, Val Acc: 0.8960, Val F1: 0.8783\n",
      "üíæ Model saved to models/bilstm_attention_best.pt\n",
      "‚úÖ Training completed in 1.5m\n",
      "‚úÖ bilstm-attention training completed successfully!\n",
      "\n",
      "============================================================\n",
      "Training Model 2/6: CNN\n",
      "============================================================\n",
      "\n",
      "üéØ Starting training for cnn...\n",
      "‚úÖ Data loaders created for traditional models\n",
      "üèãÔ∏è Training CNN-Emotion for 3 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66777c10ca54413bd9c4b48a6bbb1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.6899, Val Loss: 1.1865, Val Acc: 0.5745, Val F1: 0.5762\n",
      "üíæ Model saved to models/cnn_emotion_best.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3431259435d14ea391e8f5dd684169bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.9026, Val Loss: 0.4578, Val Acc: 0.8175, Val F1: 0.8070\n",
      "üíæ Model saved to models/cnn_emotion_best.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c66b8a0ae04e0baa5714bca42d8786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.4482, Val Loss: 0.2943, Val Acc: 0.8900, Val F1: 0.8742\n",
      "üíæ Model saved to models/cnn_emotion_best.pt\n",
      "‚úÖ Training completed in 36.8s\n",
      "‚úÖ cnn training completed successfully!\n",
      "\n",
      "============================================================\n",
      "Training Model 3/6: ROBERTA-BASE\n",
      "============================================================\n",
      "\n",
      "üéØ Starting training for roberta-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded transformer model: roberta-base\n",
      "‚úÖ Data loaders created for roberta-base models\n",
      "ü§ñ Training ROBERTA-BASE for 3 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e64165e36fe4646a219621239af3305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.6343, Val Loss: 0.2021, Val Acc: 0.9255, Val F1: 0.8996\n",
      "üíæ Model saved to models/roberta_base_best.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6a543e166343f79a1c1233a73b9414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.1865, Val Loss: 0.1702, Val Acc: 0.9390, Val F1: 0.9169\n",
      "üíæ Model saved to models/roberta_base_best.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e93ed8f4544983b5f1df223e3bc73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.1165, Val Loss: 0.1650, Val Acc: 0.9365, Val F1: 0.9161\n",
      "‚úÖ Training completed in 8.3h\n",
      "‚úÖ roberta-base training completed successfully!\n",
      "\n",
      "============================================================\n",
      "Training Model 4/6: DISTILBERT-BASE\n",
      "============================================================\n",
      "\n",
      "üéØ Starting training for distilbert-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded transformer model: distilbert-base-uncased\n",
      "‚úÖ Data loaders created for distilbert-base models\n",
      "ü§ñ Training DISTILBERT-BASE for 3 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7414ae17e944b44923e1628ad45f25a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.6543, Val Loss: 0.2231, Val Acc: 0.9225, Val F1: 0.8942\n",
      "üíæ Model saved to models/distilbert_base_best.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0663c02eac53486092038d175f5a3033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.1585, Val Loss: 0.1816, Val Acc: 0.9320, Val F1: 0.9049\n",
      "üíæ Model saved to models/distilbert_base_best.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65abad0a81d46c786b6b8d07573933f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.1052, Val Loss: 0.1528, Val Acc: 0.9390, Val F1: 0.9159\n",
      "üíæ Model saved to models/distilbert_base_best.pt\n",
      "‚úÖ Training completed in 7.6m\n",
      "‚úÖ distilbert-base training completed successfully!\n",
      "\n",
      "============================================================\n",
      "Training Model 5/6: ELECTRA-BASE\n",
      "============================================================\n",
      "\n",
      "üéØ Starting training for electra-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded transformer model: google/electra-base-discriminator\n",
      "‚úÖ Data loaders created for electra-base models\n",
      "ü§ñ Training ELECTRA-BASE for 3 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f24ea4d3134d4da28c73fe06fec209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.8643, Val Loss: 0.3157, Val Acc: 0.9165, Val F1: 0.8942\n",
      "üíæ Model saved to models/electra_base_best.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9465361bf84729b4267e21ea52c605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.2075, Val Loss: 0.1675, Val Acc: 0.9380, Val F1: 0.9139\n",
      "üíæ Model saved to models/electra_base_best.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eacbc3e70a554377b99683af398524f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.1245, Val Loss: 0.1692, Val Acc: 0.9345, Val F1: 0.9067\n",
      "‚úÖ Training completed in 14.7m\n",
      "‚úÖ electra-base training completed successfully!\n",
      "\n",
      "============================================================\n",
      "Training Model 6/6: ALBERT-BASE\n",
      "============================================================\n",
      "\n",
      "üéØ Starting training for albert-base...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded transformer model: albert-base-v2\n",
      "‚úÖ Data loaders created for albert-base models\n",
      "ü§ñ Training ALBERT-BASE for 3 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74865cfe35140b6a8944464d81fd797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.7438, Val Loss: 0.2894, Val Acc: 0.9005, Val F1: 0.8688\n",
      "üíæ Model saved to models/albert_base_best.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41ff986bbcc43958589360d0953702a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.2042, Val Loss: 0.1965, Val Acc: 0.9260, Val F1: 0.9024\n",
      "üíæ Model saved to models/albert_base_best.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f996198f93a647b3b379b51e2c6f43af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3 [Train]:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.1189, Val Loss: 0.1564, Val Acc: 0.9320, Val F1: 0.9036\n",
      "üíæ Model saved to models/albert_base_best.pt\n",
      "‚úÖ Training completed in 15.1m\n",
      "‚úÖ albert-base training completed successfully!\n",
      "\n",
      "üéâ Batch training completed!\n",
      "   Successful models: 6/6\n",
      "   Total time: 9.0h\n",
      "\n",
      "================================================================================\n",
      "üìä EVALUATION PHASE\n",
      "================================================================================\n",
      "üéØ Starting comprehensive evaluation of 6 models...\n",
      "‚úÖ Data loaders created for traditional models\n",
      "\n",
      "üìä Evaluating bilstm-attention...\n",
      "üîç Evaluating bilstm-attention on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884969b44fa74a7a98788233d25befd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ bilstm-attention Evaluation Results:\n",
      "   Accuracy: 0.8910\n",
      "   F1-Macro: 0.8572\n",
      "   F1-Weighted: 0.8936\n",
      "   Avg Inference Time: 9.03ms per batch\n",
      "‚úÖ Data loaders created for traditional models\n",
      "\n",
      "üìä Evaluating cnn...\n",
      "üîç Evaluating cnn on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf8ef2814974d2090d95ae8f39be46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ cnn Evaluation Results:\n",
      "   Accuracy: 0.8845\n",
      "   F1-Macro: 0.8483\n",
      "   F1-Weighted: 0.8871\n",
      "   Avg Inference Time: 2.40ms per batch\n",
      "‚úÖ Data loaders created for roberta-base models\n",
      "\n",
      "üìä Evaluating roberta-base...\n",
      "ü§ñ Evaluating roberta-base on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86625554f6341f1b14d4e04b5cac620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ roberta-base Evaluation Results:\n",
      "   Accuracy: 0.9285\n",
      "   F1-Macro: 0.8872\n",
      "   F1-Weighted: 0.9298\n",
      "   Avg Inference Time: 16.04ms per batch\n",
      "‚úÖ Data loaders created for distilbert-base models\n",
      "\n",
      "üìä Evaluating distilbert-base...\n",
      "ü§ñ Evaluating distilbert-base on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad6dd56048b417bbce75bb8a1ed2719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ distilbert-base Evaluation Results:\n",
      "   Accuracy: 0.9270\n",
      "   F1-Macro: 0.8854\n",
      "   F1-Weighted: 0.9267\n",
      "   Avg Inference Time: 9.24ms per batch\n",
      "‚úÖ Data loaders created for electra-base models\n",
      "\n",
      "üìä Evaluating electra-base...\n",
      "ü§ñ Evaluating electra-base on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19f48c49dc046488acd7fad9b103f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ electra-base Evaluation Results:\n",
      "   Accuracy: 0.9305\n",
      "   F1-Macro: 0.8847\n",
      "   F1-Weighted: 0.9301\n",
      "   Avg Inference Time: 19.72ms per batch\n",
      "‚úÖ Data loaders created for albert-base models\n",
      "\n",
      "üìä Evaluating albert-base...\n",
      "ü§ñ Evaluating albert-base on test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b9ed87a17e4c84bc08042cdefed0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ albert-base Evaluation Results:\n",
      "   Accuracy: 0.9345\n",
      "   F1-Macro: 0.8896\n",
      "   F1-Weighted: 0.9339\n",
      "   Avg Inference Time: 19.28ms per batch\n",
      "\n",
      "üéâ Evaluation completed for 6 models!\n",
      "\n",
      "================================================================================\n",
      "üìã ANALYSIS PHASE\n",
      "================================================================================\n",
      "\n",
      "üèÜ COMPREHENSIVE MODEL COMPARISON RESULTS:\n",
      "           Model  Accuracy  F1-Macro  F1-Weighted  Precision  Recall  Training Time (s)  Inference Time (ms)  Model Size (M)  Samples\n",
      "     albert-base    0.9345    0.8896       0.9339     0.8994  0.8811           905.4997              19.2846         11.6882     2000\n",
      "    roberta-base    0.9285    0.8872       0.9298     0.8730  0.9054         30043.7731              16.0398        124.6502     2000\n",
      " distilbert-base    0.9270    0.8854       0.9267     0.8974  0.8792           456.9058               9.2380         66.9581     2000\n",
      "    electra-base    0.9305    0.8847       0.9301     0.8939  0.8797           882.9772              19.7180        109.4869     2000\n",
      "bilstm-attention    0.8910    0.8572       0.8936     0.8291  0.8990            89.3898               9.0300          3.1567     2000\n",
      "             cnn    0.8845    0.8483       0.8871     0.8253  0.8844            36.8460               2.4035          0.9344     2000\n",
      "\n",
      "ü•á TOP 3 MODELS BY F1-MACRO SCORE:\n",
      "   1. ALBERT-BASE: 0.8896\n",
      "   2. ROBERTA-BASE: 0.8872\n",
      "   3. DISTILBERT-BASE: 0.8854\n",
      "\n",
      "================================================================================\n",
      "üé® VISUALIZATION PHASE\n",
      "================================================================================\n",
      "üìä Creating performance comparison chart...\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "#1f77b4",
           "#ff7f0e",
           "#2ca02c",
           "#8c564b",
           "#e377c2",
           "#bcbd22"
          ]
         },
         "name": "Accuracy",
         "showlegend": false,
         "text": [
          "0.891",
          "0.884",
          "0.928",
          "0.927",
          "0.930",
          "0.934"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "bilstm-attention",
          "cnn",
          "roberta-base",
          "distilbert-base",
          "electra-base",
          "albert-base"
         ],
         "xaxis": "x",
         "y": [
          0.891,
          0.8845,
          0.9285,
          0.927,
          0.9305,
          0.9345
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": [
           "#1f77b4",
           "#ff7f0e",
           "#2ca02c",
           "#8c564b",
           "#e377c2",
           "#bcbd22"
          ]
         },
         "name": "F1 Macro",
         "showlegend": false,
         "text": [
          "0.857",
          "0.848",
          "0.887",
          "0.885",
          "0.885",
          "0.890"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "bilstm-attention",
          "cnn",
          "roberta-base",
          "distilbert-base",
          "electra-base",
          "albert-base"
         ],
         "xaxis": "x2",
         "y": [
          0.8571567860867647,
          0.8482899123077665,
          0.8872293311860043,
          0.8853981301985518,
          0.8846961893866504,
          0.8896104485685351
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": [
           "#1f77b4",
           "#ff7f0e",
           "#2ca02c",
           "#8c564b",
           "#e377c2",
           "#bcbd22"
          ]
         },
         "name": "F1 Weighted",
         "showlegend": false,
         "text": [
          "0.894",
          "0.887",
          "0.930",
          "0.927",
          "0.930",
          "0.934"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          "bilstm-attention",
          "cnn",
          "roberta-base",
          "distilbert-base",
          "electra-base",
          "albert-base"
         ],
         "xaxis": "x3",
         "y": [
          0.8935867387580692,
          0.8871262735465147,
          0.9297699036477692,
          0.9267394370047652,
          0.9301433936892108,
          0.9338656215968498
         ],
         "yaxis": "y3"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Accuracy",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "F1 Macro",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "F1 Weighted",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 500,
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 20
         },
         "text": "Model Performance Comparison",
         "x": 0.5,
         "xanchor": "center"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.2888888888888889
         ],
         "tickangle": 45
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.35555555555555557,
          0.6444444444444445
         ],
         "tickangle": 45
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.7111111111111111,
          1
         ],
         "tickangle": 45
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ]
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Figure saved to visualizations/full_performance_comparison.html\n",
      "üî• Creating confusion matrices...\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "hovertemplate": "Predicted: %{x}<br>Actual: %{y}<br>Count: %{text}<br>Rate: %{z:.2f}<extra></extra>",
         "showscale": true,
         "text": {
          "bdata": "DQITAAIAFwAKAAIACgBUAjcAEAAIAAoAAQAHAJYAAAAAAAEAAQAHAAAAAAELAAAAAgAAAAAAAwDFABYAAgAAAAAAAAAGADoA",
          "dtype": "i2",
          "shape": "6, 6"
         },
         "textfont": {
          "color": "white"
         },
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise"
         ],
         "xaxis": "x",
         "y": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise"
         ],
         "yaxis": "y",
         "z": {
          "bdata": "i4ES3mjq7D9YZVIBWb6gP3kW6aMcM2w/J4jPlbxEpD8LrnHm8Z+RP3kW6aMcM2w/NCy4VLZ3jT9dHOX+FHHrP2OePlpNQrQ/w4nGQ/iSlz/DicZD+JKHPzQsuFS2d40/AqHkTtHCeT/hDAgld4qmP67sc0hNMO4/AAAAAAAAAAAAAAAAAAAAAAKh5E7Rwnk/yh2g3AHKbT8RGgyhwRCaPwAAAAAAAAAAyh2g3AHK7T97FK5H4XqkPwAAAAAAAAAAkiRJkiRJgj8AAAAAAAAAAAAAAAAAAAAA27Zt27Ztiz9JkiRJkiTsP0mSJEmSJLk/CB988MEHnz8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABGF1100UW3Px988MEHH+w/",
          "dtype": "f8",
          "shape": "6, 6"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "hovertemplate": "Predicted: %{x}<br>Actual: %{y}<br>Count: %{text}<br>Rate: %{z:.2f}<extra></extra>",
         "showscale": false,
         "text": {
          "bdata": "GQIKAAQAFQAHAAIADgBQAjwAEwABAAkAAwAMAIsABQAAAAAABgAFAAAA/wAIAAEACAAAAAAACAC7ABUAAAACAAAAAAAFADsA",
          "dtype": "i2",
          "shape": "6, 6"
         },
         "textfont": {
          "color": "white"
         },
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise"
         ],
         "xaxis": "x2",
         "y": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise"
         ],
         "yaxis": "y2",
         "z": {
          "bdata": "EvjpiZuT7T8LrnHm8Z+RP3kW6aMcM3w/v/aQy4qBoj+q82sPuayIP3kW6aMcM2w/irhNO5mglD9Jj10O70HrPychir/IGbY/l8N70Ib+mz/DicZD+JJXP/taP0xXhYo/wXgr+xxSkz/BeCv7HFKzP9hGrEuP+es/oeRO0cIZoD8AAAAAAAAAAAAAAAAAAAAAWBZ4ZYFXlj+eEuQpQZ6SPwAAAAAAAAAArH3D2jes7T/KHaDcAcqdP8odoNwBym0/kiRJkiRJoj8AAAAAAAAAAAAAAAAAAAAAkiRJkiRJoj9u27Zt27bqPwAAAAAAALg/AAAAAAAAAAAIH3zwwQefPwAAAAAAAAAAAAAAAAAAAABlk0022WSzP5tssskmm+w/",
          "dtype": "f8",
          "shape": "6, 6"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "hovertemplate": "Predicted: %{x}<br>Actual: %{y}<br>Count: %{text}<br>Rate: %{z:.2f}<extra></extra>",
         "showscale": false,
         "text": {
          "bdata": "MQICAAAACAAKAAAABACHAiEAAgABAAgAAAAPAI8AAQAAAAAACAACAAAA/gALAAAABgAAAAAAAgDFABMAAwAAAAAAAAAIADcA",
          "dtype": "i2",
          "shape": "6, 6"
         },
         "textfont": {
          "color": "white"
         },
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise"
         ],
         "xaxis": "x3",
         "y": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise"
         ],
         "yaxis": "y3",
         "z": {
          "bdata": "H+WY4QDm7j95FumjHDNsPwAAAAAAAAAAeRbpoxwzjD8LrnHm8Z+RPwAAAAAAAAAAw4nGQ/iSdz8WY6W5OMrtPxG+5AWQT6g/w4nGQ/iSZz/DicZD+JJXP8OJxkP4koc/AAAAAAAAAADyVvY5pCa4P+BrI9alx+w/AqHkTtHCeT8AAAAAAAAAAAAAAAAAAAAAyh2g3AHKnT/KHaDcAcp9PwAAAAAAAAAAjt3m2G2O7T97FK5H4XqkPwAAAAAAAAAA27Zt27Ztmz8AAAAAAAAAAAAAAAAAAAAAkiRJkiRJgj9JkiRJkiTsP27btm3btrU/RhdddNFFpz8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIH3zwwQe/P6uqqqqqquo/",
          "dtype": "f8",
          "shape": "6, 6"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "hovertemplate": "Predicted: %{x}<br>Actual: %{y}<br>Count: %{text}<br>Rate: %{z:.2f}<extra></extra>",
         "showscale": false,
         "text": {
          "bdata": "MQICAAEACgAHAAAAAgCMAiAABQAAAAQAAAAWAIcAAgAAAAAACwADAAAA+gALAAAABQAAAAAABQDUAAIAAgAEAAAAAAAQACwA",
          "dtype": "i2",
          "shape": "6, 6"
         },
         "textfont": {
          "color": "white"
         },
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise"
         ],
         "xaxis": "x4",
         "y": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise"
         ],
         "yaxis": "y4",
         "z": {
          "bdata": "H+WY4QDm7j95FumjHDNsP3kW6aMcM1w/C65x5vGfkT+q82sPuayIPwAAAAAAAAAAw4nGQ/iSZz9u004mKAXuP8OJxkP4kqc/NCy4VLZ3fT8AAAAAAAAAAMOJxkP4knc/AAAAAAAAAACxLj3m77XBP9AhNcF4K+s/AqHkTtHCiT8AAAAAAAAAAAAAAAAAAAAAexSuR+F6pD9YFnhlgVeGPwAAAAAAAAAAF1100UUX7T97FK5H4XqkPwAAAAAAAAAAt23btm3blj8AAAAAAAAAAAAAAAAAAAAAt23btm3blj+SJEmSJEnuP5IkSZIkSYI/CB988MEHnz8IH3zwwQevPwAAAAAAAAAAAAAAAAAAAAAIH3zwwQfPP1VVVVVVVeU/",
          "dtype": "f8",
          "shape": "6, 6"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "hovertemplate": "Predicted: %{x}<br>Actual: %{y}<br>Count: %{text}<br>Rate: %{z:.2f}<extra></extra>",
         "showscale": false,
         "text": {
          "bdata": "OQIAAAAACAAEAAAAAwCMAiEAAwAAAAQAAAAVAIoAAAAAAAAADQADAAAA+wAIAAAABgAAAAAABQDQAAUAAgABAAAAAgASACsA",
          "dtype": "i2",
          "shape": "6, 6"
         },
         "textfont": {
          "color": "white"
         },
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise"
         ],
         "xaxis": "x5",
         "y": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise"
         ],
         "yaxis": "y5",
         "z": {
          "bdata": "eYkoVM1W7z8AAAAAAAAAAAAAAAAAAAAAeRbpoxwzjD95FumjHDN8PwAAAAAAAAAAUufUMjqucT9u004mKAXuPxG+5AWQT6g/UufUMjqucT8AAAAAAAAAAMOJxkP4knc/AAAAAAAAAACpCcZb2efAP5Z9DqkJxus/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANBhCgyE0qD9YFnhlgVeGPwAAAAAAAAAANf1Q0w817T/KHaDcAcqdPwAAAAAAAAAA27Zt27Ztmz8AAAAAAAAAAAAAAAAAAAAAt23btm3blj9u27Zt27btP7dt27Zt25Y/CB988MEHnz8IH3zwwQePPwAAAAAAAAAACB988MEHnz900UUXXXTRP9lkk0022eQ/",
          "dtype": "f8",
          "shape": "6, 6"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgb(247,251,255)"
          ],
          [
           0.125,
           "rgb(222,235,247)"
          ],
          [
           0.25,
           "rgb(198,219,239)"
          ],
          [
           0.375,
           "rgb(158,202,225)"
          ],
          [
           0.5,
           "rgb(107,174,214)"
          ],
          [
           0.625,
           "rgb(66,146,198)"
          ],
          [
           0.75,
           "rgb(33,113,181)"
          ],
          [
           0.875,
           "rgb(8,81,156)"
          ],
          [
           1,
           "rgb(8,48,107)"
          ]
         ],
         "hovertemplate": "Predicted: %{x}<br>Actual: %{y}<br>Count: %{text}<br>Rate: %{z:.2f}<extra></extra>",
         "showscale": false,
         "text": {
          "bdata": "OQIEAAAABgACAAAAAACZAhkABAAAAAEAAAAbAIMAAQAAAAAACgABAAAABAEEAAAABwAAAAAACADGAAsAAQAHAAAAAQALAC4A",
          "dtype": "i2",
          "shape": "6, 6"
         },
         "textfont": {
          "color": "white"
         },
         "texttemplate": "%{text}",
         "type": "heatmap",
         "x": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise"
         ],
         "xaxis": "x6",
         "y": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise"
         ],
         "yaxis": "y6",
         "z": {
          "bdata": "eYkoVM1W7z95FumjHDN8PwAAAAAAAAAA29DuelUmhT95FumjHDNsPwAAAAAAAAAAAAAAAAAAAADuXQd0Y57uP6Ab8/TRaqI/w4nGQ/iSdz8AAAAAAAAAAMOJxkP4klc/AAAAAAAAAADZ55CaYLzFP8j8vTZiXeo/AqHkTtHCeT8AAAAAAAAAAAAAAAAAAAAAnhLkKUGeoj/KHaDcAcptPwAAAAAAAAAAQZ4S5ClB7j/KHaDcAcqNPwAAAAAAAAAAAAAAAAAAoD8AAAAAAAAAAAAAAAAAAAAAkiRJkiRJoj+SJEmSJEnsP0mSJEmSJKk/CB988MEHjz8nm2yyySa7PwAAAAAAAAAACB988MEHjz9VVVVVVVXFP0422WSTTeY/",
          "dtype": "f8",
          "shape": "6, 6"
         }
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "BILSTM-ATTENTION",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "CNN",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "ROBERTA-BASE",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "DISTILBERT-BASE",
          "x": 0.14444444444444446,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "ELECTRA-BASE",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "ALBERT-BASE",
          "x": 0.8555555555555556,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 500,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 20
         },
         "text": "Confusion Matrices Comparison",
         "x": 0.5,
         "xanchor": "center"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.2888888888888889
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.35555555555555557,
          0.6444444444444445
         ]
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0.7111111111111111,
          1
         ]
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0,
          0.2888888888888889
         ]
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0.35555555555555557,
          0.6444444444444445
         ]
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.7111111111111111,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.625,
          1
         ]
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.375
         ]
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.375
         ]
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.375
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Figure saved to visualizations/confusion_matrices.html\n",
      "üìà Creating training curves...\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "#1f77b4"
         },
         "mode": "lines+markers",
         "name": "bilstm-attention",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x",
         "y": [
          1.5706504353284836,
          0.8874204396009445,
          0.570047363743186
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "#1f77b4"
         },
         "mode": "lines+markers",
         "name": "bilstm-attention",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x2",
         "y": [
          0.8625277225971222,
          0.4114402347803116,
          0.2430015257075429
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "#1f77b4"
         },
         "mode": "lines+markers",
         "name": "bilstm-attention",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x3",
         "y": [
          0.625,
          0.847,
          0.896
         ],
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "#1f77b4"
         },
         "mode": "lines+markers",
         "name": "bilstm-attention",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x4",
         "y": [
          0.636041454955027,
          0.829528133952679,
          0.8783172008814782
         ],
         "yaxis": "y4"
        },
        {
         "line": {
          "color": "#ff7f0e"
         },
         "mode": "lines+markers",
         "name": "cnn",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x",
         "y": [
          1.6899129163622857,
          0.9026145592927933,
          0.4481842806469649
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "#ff7f0e"
         },
         "mode": "lines+markers",
         "name": "cnn",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x2",
         "y": [
          1.1864829955101013,
          0.45783141714334485,
          0.29434272852540017
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "#ff7f0e"
         },
         "mode": "lines+markers",
         "name": "cnn",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x3",
         "y": [
          0.5745,
          0.8175,
          0.89
         ],
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "#ff7f0e"
         },
         "mode": "lines+markers",
         "name": "cnn",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x4",
         "y": [
          0.5762434351747036,
          0.8070306047429455,
          0.8742062539853168
         ],
         "yaxis": "y4"
        },
        {
         "line": {
          "color": "#2ca02c"
         },
         "mode": "lines+markers",
         "name": "roberta-base",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x",
         "y": [
          0.6343309431374073,
          0.18646225048182533,
          0.11645788523904048
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "#2ca02c"
         },
         "mode": "lines+markers",
         "name": "roberta-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x2",
         "y": [
          0.20206749084219336,
          0.17020325089152902,
          0.1650210771933198
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "#2ca02c"
         },
         "mode": "lines+markers",
         "name": "roberta-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x3",
         "y": [
          0.9255,
          0.939,
          0.9365
         ],
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "#2ca02c"
         },
         "mode": "lines+markers",
         "name": "roberta-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x4",
         "y": [
          0.8995659517083663,
          0.9168525427704303,
          0.916113989515158
         ],
         "yaxis": "y4"
        },
        {
         "line": {
          "color": "#8c564b"
         },
         "mode": "lines+markers",
         "name": "distilbert-base",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x",
         "y": [
          0.6543006991520524,
          0.15854404163104482,
          0.10521853788709268
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "#8c564b"
         },
         "mode": "lines+markers",
         "name": "distilbert-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x2",
         "y": [
          0.22307370306551458,
          0.18160377792827784,
          0.15275257063750178
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "#8c564b"
         },
         "mode": "lines+markers",
         "name": "distilbert-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x3",
         "y": [
          0.9225,
          0.932,
          0.939
         ],
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "#8c564b"
         },
         "mode": "lines+markers",
         "name": "distilbert-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x4",
         "y": [
          0.8942255385597385,
          0.904913865004732,
          0.9158915364267353
         ],
         "yaxis": "y4"
        },
        {
         "line": {
          "color": "#e377c2"
         },
         "mode": "lines+markers",
         "name": "electra-base",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x",
         "y": [
          0.8643004686571658,
          0.2075417934190482,
          0.12449662562296726
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "#e377c2"
         },
         "mode": "lines+markers",
         "name": "electra-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x2",
         "y": [
          0.31568072667717934,
          0.16747305877879262,
          0.16921883113961667
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "#e377c2"
         },
         "mode": "lines+markers",
         "name": "electra-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x3",
         "y": [
          0.9165,
          0.938,
          0.9345
         ],
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "#e377c2"
         },
         "mode": "lines+markers",
         "name": "electra-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x4",
         "y": [
          0.8941830242212689,
          0.9139376015350908,
          0.9067313197164196
         ],
         "yaxis": "y4"
        },
        {
         "line": {
          "color": "#bcbd22"
         },
         "mode": "lines+markers",
         "name": "albert-base",
         "showlegend": true,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x",
         "y": [
          0.7438139901543036,
          0.2042448419891298,
          0.11888445845234673
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "#bcbd22"
         },
         "mode": "lines+markers",
         "name": "albert-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x2",
         "y": [
          0.289436542391777,
          0.19653903578594328,
          0.15642185477353632
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "#bcbd22"
         },
         "mode": "lines+markers",
         "name": "albert-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x3",
         "y": [
          0.9005,
          0.926,
          0.932
         ],
         "yaxis": "y3"
        },
        {
         "line": {
          "color": "#bcbd22"
         },
         "mode": "lines+markers",
         "name": "albert-base",
         "showlegend": false,
         "type": "scatter",
         "x": [
          1,
          2,
          3
         ],
         "xaxis": "x4",
         "y": [
          0.8687978635145751,
          0.9023706143977531,
          0.9035968285381338
         ],
         "yaxis": "y4"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Training Loss",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Validation Loss",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Validation Accuracy",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Validation F1-Score",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 600,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 20
         },
         "text": "Training Progress Comparison",
         "x": 0.5,
         "xanchor": "center"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.625,
          1
         ],
         "title": {
          "text": "Loss"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.625,
          1
         ],
         "title": {
          "text": "Loss"
         }
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0,
          0.375
         ],
         "title": {
          "text": "Accuracy"
         }
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0,
          0.375
         ],
         "title": {
          "text": "F1-Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Figure saved to visualizations/training_curves.html\n",
      "üéØ Creating radar chart...\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "fill": "toself",
         "fillcolor": "#1f77b4",
         "line": {
          "color": "#1f77b4"
         },
         "name": "BILSTM-ATTENTION",
         "opacity": 0.3,
         "r": [
          0.9358288770053476,
          0.9003021148036254,
          0.819672131147541,
          0.893542757417103,
          0.8640350877192983,
          0.7295597484276729,
          0.9358288770053476
         ],
         "theta": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise",
          "sadness"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "fillcolor": "#ff7f0e",
         "line": {
          "color": "#ff7f0e"
         },
         "name": "CNN",
         "opacity": 0.3,
         "r": [
          0.9347258485639687,
          0.8996960486322189,
          0.7679558011049724,
          0.8747855917667239,
          0.8657407407407407,
          0.7468354430379747,
          0.9347258485639687
         ],
         "theta": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise",
          "sadness"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "fillcolor": "#2ca02c",
         "line": {
          "color": "#2ca02c"
         },
         "name": "ROBERTA-BASE",
         "opacity": 0.3,
         "r": [
          0.9647463456577816,
          0.9507714915503307,
          0.8537313432835821,
          0.9372693726937269,
          0.8736141906873615,
          0.7432432432432432,
          0.9647463456577816
         ],
         "theta": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise",
          "sadness"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "fillcolor": "#8c564b",
         "line": {
          "color": "#8c564b"
         },
         "name": "DISTILBERT-BASE",
         "opacity": 0.3,
         "r": [
          0.9655765920826161,
          0.9462989840348331,
          0.8256880733944955,
          0.9140767824497258,
          0.902127659574468,
          0.7586206896551724,
          0.9655765920826161
         ],
         "theta": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise",
          "sadness"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "fillcolor": "#e377c2",
         "line": {
          "color": "#e377c2"
         },
         "name": "ELECTRA-BASE",
         "opacity": 0.3,
         "r": [
          0.969335604770017,
          0.9504373177842566,
          0.8363636363636363,
          0.9227941176470589,
          0.9004329004329005,
          0.7288135593220338,
          0.969335604770017
         ],
         "theta": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise",
          "sadness"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "fillcolor": "#bcbd22",
         "line": {
          "color": "#bcbd22"
         },
         "name": "ALBERT-BASE",
         "opacity": 0.3,
         "r": [
          0.9743150684931506,
          0.9506790564689064,
          0.8317460317460318,
          0.9369369369369369,
          0.9020501138952164,
          0.7419354838709677,
          0.9743150684931506
         ],
         "theta": [
          "sadness",
          "joy",
          "love",
          "anger",
          "fear",
          "surprise",
          "sadness"
         ],
         "type": "scatterpolar"
        }
       ],
       "layout": {
        "height": 600,
        "polar": {
         "radialaxis": {
          "range": [
           0,
           1
          ],
          "visible": true
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 20
         },
         "text": "Per-Emotion F1-Score Comparison",
         "x": 0.5,
         "xanchor": "center"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Figure saved to visualizations/radar_chart.html\n",
      "‚ö° Creating efficiency analysis...\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "#1f77b4",
           "#ff7f0e",
           "#2ca02c",
           "#8c564b",
           "#e377c2",
           "#bcbd22"
          ],
          "size": 10
         },
         "mode": "markers+text",
         "name": "Models",
         "showlegend": false,
         "text": [
          "bilstm-attention",
          "cnn",
          "roberta-base",
          "distilbert-base",
          "electra-base",
          "albert-base"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          89.38981914520264,
          36.8459575176239,
          30043.77309536934,
          456.9057722091675,
          882.9772217273712,
          905.4996945858002
         ],
         "xaxis": "x",
         "y": [
          0.8571567860867647,
          0.8482899123077665,
          0.8872293311860043,
          0.8853981301985518,
          0.8846961893866504,
          0.8896104485685351
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": [
           "#1f77b4",
           "#ff7f0e",
           "#2ca02c",
           "#8c564b",
           "#e377c2",
           "#bcbd22"
          ],
          "size": 10
         },
         "mode": "markers+text",
         "name": "Models",
         "showlegend": false,
         "text": [
          "bilstm-attention",
          "cnn",
          "roberta-base",
          "distilbert-base",
          "electra-base",
          "albert-base"
         ],
         "textposition": "top center",
         "type": "scatter",
         "x": [
          3.156735,
          0.934398,
          124.650246,
          66.958086,
          109.486854,
          11.688198
         ],
         "xaxis": "x2",
         "y": [
          0.8571567860867647,
          0.8482899123077665,
          0.8872293311860043,
          0.8853981301985518,
          0.8846961893866504,
          0.8896104485685351
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Training Time vs Performance",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Model Size vs Performance",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 500,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 20
         },
         "text": "Model Efficiency Analysis",
         "x": 0.5,
         "xanchor": "center"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ],
         "title": {
          "text": "Training Time (seconds)"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ],
         "title": {
          "text": "Model Size (M parameters)"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "F1-Macro Score"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "F1-Macro Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Figure saved to visualizations/efficiency_analysis.html\n",
      "üèÖ Creating model ranking...\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": [
           "#bcbd22",
           "#2ca02c",
           "#8c564b",
           "#e377c2",
           "#1f77b4",
           "#ff7f0e"
          ]
         },
         "orientation": "h",
         "text": [
          "0.890",
          "0.887",
          "0.885",
          "0.885",
          "0.857",
          "0.848"
         ],
         "textposition": "auto",
         "type": "bar",
         "x": [
          0.8896104485685351,
          0.8872293311860043,
          0.8853981301985518,
          0.8846961893866504,
          0.8571567860867647,
          0.8482899123077665
         ],
         "y": [
          "albert-base",
          "roberta-base",
          "distilbert-base",
          "electra-base",
          "bilstm-attention",
          "cnn"
         ]
        }
       ],
       "layout": {
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "size": 20
         },
         "text": "Model Ranking by F1 Macro",
         "x": 0.5,
         "xanchor": "center"
        },
        "xaxis": {
         "title": {
          "text": "F1 Macro"
         }
        },
        "yaxis": {
         "title": {
          "text": "Models"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Figure saved to visualizations/model_ranking.html\n",
      "\n",
      "üíæ Saving results...\n",
      "üíæ Results saved to results/full_comparison_results.json\n",
      "\n",
      "================================================================================\n",
      "üéâ FULL COMPARISON COMPLETED!\n",
      "================================================================================\n",
      "   Total time: 9.0h\n",
      "   Models evaluated: 6\n",
      "   Best model: ALBERT-BASE (F1: 0.8896)\n",
      "   Results saved to: results/\n",
      "   Visualizations saved to: visualizations/\n",
      "\n",
      "‚ö° Full comparison pipeline ready!\n",
      "   To run full comparison, set FULL_CONFIG['run_full_comparison'] = True and execute the cell above.\n"
     ]
    }
   ],
   "source": [
    "def run_full_comparison():\n",
    "    \"\"\"Run comprehensive model comparison\"\"\"\n",
    "    if not FULL_CONFIG['run_full_comparison']:\n",
    "        print(\"‚ö†Ô∏è Full comparison is disabled. Set FULL_CONFIG['run_full_comparison'] = True to enable.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"üöÄ Starting full model comparison with {len(all_models)} models...\")\n",
    "    print(f\"   This may take a while depending on your hardware.\")\n",
    "\n",
    "    # Check if data is ready\n",
    "    if data_manager.dataset is None:\n",
    "        print(\"‚ùå Dataset not loaded. Please run data loading cells first.\")\n",
    "        return None\n",
    "\n",
    "    total_start_time = time.time()\n",
    "\n",
    "    # Train all models\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üèãÔ∏è TRAINING PHASE\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    training_results = trainer.train_multiple_models(\n",
    "        all_models,\n",
    "        data_manager,\n",
    "        epochs=FULL_CONFIG['epochs'],\n",
    "        batch_size=FULL_CONFIG['batch_size']\n",
    "    )\n",
    "\n",
    "    # Evaluate all models\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä EVALUATION PHASE\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    evaluation_results = evaluator.evaluate_all_models(\n",
    "        training_results,\n",
    "        data_manager,\n",
    "        batch_size=FULL_CONFIG['batch_size']\n",
    "    )\n",
    "\n",
    "    if not evaluation_results:\n",
    "        print(\"‚ùå No successful evaluations to analyze\")\n",
    "        return None\n",
    "\n",
    "    # Generate comprehensive analysis\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìã ANALYSIS PHASE\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Comparison report\n",
    "    comparison_df = evaluator.generate_comparison_report()\n",
    "    print(\"\\nüèÜ COMPREHENSIVE MODEL COMPARISON RESULTS:\")\n",
    "    print(comparison_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "    # Best models\n",
    "    best_models = evaluator.get_best_models(metric='f1_macro', top_k=3)\n",
    "    print(\"\\nü•á TOP 3 MODELS BY F1-MACRO SCORE:\")\n",
    "    for i, (model_name, result) in enumerate(best_models, 1):\n",
    "        print(f\"   {i}. {model_name.upper()}: {result['f1_macro']:.4f}\")\n",
    "\n",
    "    # Generate all visualizations\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üé® VISUALIZATION PHASE\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # 1. Performance comparison\n",
    "    print(\"üìä Creating performance comparison chart...\")\n",
    "    perf_fig = visualizer.plot_performance_comparison(evaluation_results)\n",
    "    if perf_fig:\n",
    "        perf_fig.show()\n",
    "        visualizer.save_figure(perf_fig, 'full_performance_comparison.html')\n",
    "\n",
    "    # 2. Confusion matrices\n",
    "    print(\"üî• Creating confusion matrices...\")\n",
    "    cm_fig = visualizer.plot_confusion_matrices(evaluation_results)\n",
    "    if cm_fig:\n",
    "        cm_fig.show()\n",
    "        visualizer.save_figure(cm_fig, 'confusion_matrices.html')\n",
    "\n",
    "    # 3. Training curves\n",
    "    print(\"üìà Creating training curves...\")\n",
    "    training_history = {name: result['history'] for name, result in training_results.items()\n",
    "                      if result['status'] == 'success'}\n",
    "    if training_history:\n",
    "        curves_fig = visualizer.plot_training_curves(training_history)\n",
    "        if curves_fig:\n",
    "            curves_fig.show()\n",
    "            visualizer.save_figure(curves_fig, 'training_curves.html')\n",
    "\n",
    "    # 4. Radar chart\n",
    "    print(\"üéØ Creating radar chart...\")\n",
    "    radar_fig = visualizer.plot_radar_chart(evaluation_results)\n",
    "    if radar_fig:\n",
    "        radar_fig.show()\n",
    "        visualizer.save_figure(radar_fig, 'radar_chart.html')\n",
    "\n",
    "    # 5. Efficiency analysis\n",
    "    print(\"‚ö° Creating efficiency analysis...\")\n",
    "    eff_fig = visualizer.plot_efficiency_analysis(evaluation_results)\n",
    "    if eff_fig:\n",
    "        eff_fig.show()\n",
    "        visualizer.save_figure(eff_fig, 'efficiency_analysis.html')\n",
    "\n",
    "    # 6. Model ranking\n",
    "    print(\"üèÖ Creating model ranking...\")\n",
    "    ranking_fig = visualizer.create_model_ranking(evaluation_results)\n",
    "    if ranking_fig:\n",
    "        ranking_fig.show()\n",
    "        visualizer.save_figure(ranking_fig, 'model_ranking.html')\n",
    "\n",
    "    # Save all results\n",
    "    print(\"\\nüíæ Saving results...\")\n",
    "    evaluator.save_results('full_comparison_results.json')\n",
    "    comparison_df.to_csv('results/model_comparison.csv', index=False)\n",
    "\n",
    "    total_time = time.time() - total_start_time\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üéâ FULL COMPARISON COMPLETED!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"   Total time: {format_time(total_time)}\")\n",
    "    print(f\"   Models evaluated: {len(evaluation_results)}\")\n",
    "    print(f\"   Best model: {best_models[0][0].upper()} (F1: {best_models[0][1]['f1_macro']:.4f})\")\n",
    "    print(f\"   Results saved to: results/\")\n",
    "    print(f\"   Visualizations saved to: visualizations/\")\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "# Uncomment the line below to run full comparison\n",
    "full_results = run_full_comparison()\n",
    "\n",
    "print(\"\\n‚ö° Full comparison pipeline ready!\")\n",
    "print(\"   To run full comparison, set FULL_CONFIG['run_full_comparison'] = True and execute the cell above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ty3p1Mdgpuo"
   },
   "source": [
    "### 9.3 Custom Model Selection\n",
    "\n",
    "Run comparison with custom model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_custom_comparison(selected_models, epochs=2, batch_size=16):\n",
    "#     \"\"\"Run comparison with custom model selection\"\"\"\n",
    "#     print(f\"üéØ Running custom comparison with {len(selected_models)} models...\")\n",
    "#     print(f\"   Models: {selected_models}\")\n",
    "\n",
    "#     # Validate model availability\n",
    "#     available_models = []\n",
    "#     for model in selected_models:\n",
    "#         if model in ['bilstm-attention', 'cnn']:\n",
    "#             if data_manager.vocab is not None:\n",
    "#                 available_models.append(model)\n",
    "#             else:\n",
    "#                 print(f\"‚ö†Ô∏è Skipping {model}: vocabulary not built\")\n",
    "#         elif model in data_manager.tokenizers:\n",
    "#             available_models.append(model)\n",
    "#         else:\n",
    "#             print(f\"‚ö†Ô∏è Skipping {model}: tokenizer not available\")\n",
    "\n",
    "#     if not available_models:\n",
    "#         print(\"‚ùå No available models to compare\")\n",
    "#         return None\n",
    "\n",
    "#     print(f\"‚úÖ Available models: {available_models}\")\n",
    "\n",
    "#     # Train models\n",
    "#     training_results = trainer.train_multiple_models(\n",
    "#         available_models, data_manager, epochs=epochs, batch_size=batch_size\n",
    "#     )\n",
    "\n",
    "#     # Evaluate models\n",
    "#     evaluation_results = evaluator.evaluate_all_models(\n",
    "#         training_results, data_manager, batch_size=batch_size\n",
    "#     )\n",
    "\n",
    "#     if evaluation_results:\n",
    "#         # Generate report\n",
    "#         comparison_df = evaluator.generate_comparison_report()\n",
    "#         print(\"\\nüìä Custom Comparison Results:\")\n",
    "#         print(comparison_df.to_string(index=False, float_format='%.4f'))\n",
    "\n",
    "#         # Create key visualizations\n",
    "#         perf_fig = visualizer.plot_performance_comparison(evaluation_results)\n",
    "#         if perf_fig:\n",
    "#             perf_fig.show()\n",
    "\n",
    "#         return evaluation_results\n",
    "\n",
    "#     return None\n",
    "\n",
    "# # Example: Compare a few specific models\n",
    "# custom_results = run_custom_comparison(['bilstm-attention', 'roberta-base', 'distilbert-base', 'cnn'])\n",
    "\n",
    "# print(\"üõ†Ô∏è Custom comparison function ready!\")\n",
    "# print(\"   Example usage: run_custom_comparison(['bilstm-attention', 'roberta-base', 'distilbert-base'])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyaaQJrwgpup"
   },
   "source": [
    "## 10. Results and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJYYoXRlgpup"
   },
   "source": [
    "### 10.1 Load and Display Previous Results\n",
    "\n",
    "If you have run the comparison before, you can load and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loaded results for 6 models from quick_test_results.json\n",
      "\n",
      "üèÜ MODEL PERFORMANCE SUMMARY:\n",
      "           Model Accuracy F1-Macro F1-Weighted Training Time Inference Time Model Size\n",
      "    ROBERTA-BASE   0.9045   0.8585      0.9053          4.5m        15.51ms     124.7M\n",
      " DISTILBERT-BASE   0.9070   0.8550      0.9053          2.3m         8.36ms      67.0M\n",
      "     ALBERT-BASE   0.8935   0.8420      0.8926          5.0m        18.22ms      11.7M\n",
      "    ELECTRA-BASE   0.8370   0.6970      0.8176          4.7m        18.92ms     109.5M\n",
      "BILSTM-ATTENTION   0.5110   0.5121      0.5161         18.7s         8.74ms       3.2M\n",
      "             CNN   0.4005   0.4081      0.3899          8.0s         1.97ms       0.9M\n",
      "\n",
      "ü•á BEST PERFORMING MODEL: ROBERTA-BASE\n",
      "   F1-Macro Score: 0.8585\n",
      "   Accuracy: 0.9045\n",
      "   Training Time: 4.5m\n",
      "   Model Size: 124.7M parameters\n",
      "\n",
      "==================================================\n",
      "üí° ALTERNATIVE: Display quick test results\n",
      "==================================================\n",
      "If you have run the quick test, use:\n",
      "display_current_results(quick_results)\n",
      "\n",
      "üéØ Found quick test results! Displaying...\n",
      "üìä Loaded results for 6 models from current session\n",
      "\n",
      "üèÜ MODEL PERFORMANCE SUMMARY:\n",
      "           Model Accuracy F1-Macro F1-Weighted Training Time Inference Time Model Size\n",
      "    ROBERTA-BASE   0.9045   0.8585      0.9053          4.5m        15.51ms     124.7M\n",
      " DISTILBERT-BASE   0.9070   0.8550      0.9053          2.3m         8.36ms      67.0M\n",
      "     ALBERT-BASE   0.8935   0.8420      0.8926          5.0m        18.22ms      11.7M\n",
      "    ELECTRA-BASE   0.8370   0.6970      0.8176          4.7m        18.92ms     109.5M\n",
      "BILSTM-ATTENTION   0.5110   0.5121      0.5161         18.7s         8.74ms       3.2M\n",
      "             CNN   0.4005   0.4081      0.3899          8.0s         1.97ms       0.9M\n",
      "\n",
      "ü•á BEST PERFORMING MODEL: ROBERTA-BASE\n",
      "   F1-Macro Score: 0.8585\n",
      "   Accuracy: 0.9045\n",
      "   Training Time: 4.5m\n",
      "   Model Size: 124.7M parameters\n"
     ]
    }
   ],
   "source": [
    "# def display_saved_results(filename='full_comparison_results.json'):\n",
    "def display_saved_results(filename='quick_test_results.json'):\n",
    "    \"\"\"Display previously saved results with fallback options\"\"\"\n",
    "    results = load_results(filename)\n",
    "\n",
    "    if not results:\n",
    "        print(f\"‚ùå No saved results found in {filename}\")\n",
    "\n",
    "        # Try alternative result files\n",
    "        alternative_files = [\n",
    "            'quick_test_results.json',\n",
    "            'evaluation_results.json',\n",
    "            'custom_results.json'\n",
    "        ]\n",
    "\n",
    "        print(\"üîç Checking for alternative result files...\")\n",
    "        for alt_file in alternative_files:\n",
    "            alt_results = load_results(alt_file)\n",
    "            if alt_results:\n",
    "                print(f\"‚úÖ Found results in {alt_file}\")\n",
    "                return display_results_data(alt_results, alt_file)\n",
    "\n",
    "        print(\"   Run the comparison pipeline first to generate results.\")\n",
    "        print(\"   Available options:\")\n",
    "        print(\"   ‚Ä¢ quick_results = run_quick_test()  # For quick test\")\n",
    "        print(\"   ‚Ä¢ custom_results = run_custom_comparison(['model1', 'model2'])  # For custom selection\")\n",
    "        print(\"   ‚Ä¢ Set FULL_CONFIG['run_full_comparison'] = True and run full pipeline\")\n",
    "        return None\n",
    "\n",
    "    return display_results_data(results, filename)\n",
    "\n",
    "def display_results_data(results, filename):\n",
    "    \"\"\"Display results data with formatting\"\"\"\n",
    "    print(f\"üìä Loaded results for {len(results)} models from {filename}\")\n",
    "\n",
    "    # Create summary table\n",
    "    summary_data = []\n",
    "    for model_name, result in results.items():\n",
    "        summary_data.append({\n",
    "            'Model': model_name.upper(),\n",
    "            'Accuracy': f\"{result['accuracy']:.4f}\",\n",
    "            'F1-Macro': f\"{result['f1_macro']:.4f}\",\n",
    "            'F1-Weighted': f\"{result['f1_weighted']:.4f}\",\n",
    "            'Training Time': format_time(result.get('training_time', 0)),\n",
    "            'Inference Time': f\"{result['avg_inference_time']*1000:.2f}ms\",\n",
    "            'Model Size': f\"{result.get('model_size', 0)/1e6:.1f}M\"\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df = summary_df.sort_values('F1-Macro', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    print(\"\\nüèÜ MODEL PERFORMANCE SUMMARY:\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "\n",
    "    # Best model analysis\n",
    "    if len(summary_df) > 0:\n",
    "        best_model = summary_df.iloc[0]\n",
    "        print(f\"\\nü•á BEST PERFORMING MODEL: {best_model['Model']}\")\n",
    "        print(f\"   F1-Macro Score: {best_model['F1-Macro']}\")\n",
    "        print(f\"   Accuracy: {best_model['Accuracy']}\")\n",
    "        print(f\"   Training Time: {best_model['Training Time']}\")\n",
    "        print(f\"   Model Size: {best_model['Model Size']} parameters\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def display_current_results(results_variable):\n",
    "    \"\"\"Display results from a variable (like quick_results)\"\"\"\n",
    "    if results_variable is None:\n",
    "        print(\"‚ùå No results to display. The variable is None.\")\n",
    "        return None\n",
    "\n",
    "    if not isinstance(results_variable, dict):\n",
    "        print(\"‚ùå Invalid results format. Expected dictionary.\")\n",
    "        return None\n",
    "\n",
    "    return display_results_data(results_variable, \"current session\")\n",
    "\n",
    "# Try to load and display results\n",
    "saved_results = display_saved_results()\n",
    "\n",
    "# If you have quick_results from the previous test, you can display them:\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üí° ALTERNATIVE: Display quick test results\")\n",
    "print(\"=\"*50)\n",
    "print(\"If you have run the quick test, use:\")\n",
    "print(\"display_current_results(quick_results)\")\n",
    "\n",
    "# Try to display quick results if available\n",
    "try:\n",
    "    if 'quick_results' in globals() and quick_results:\n",
    "        print(\"\\nüéØ Found quick test results! Displaying...\")\n",
    "        display_current_results(quick_results)\n",
    "except NameError:\n",
    "    print(\"\\n‚ö†Ô∏è No quick_results variable found. Run the quick test first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcxWSKmSgpup"
   },
   "source": [
    "### 10.2 Model Analysis and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DETAILED ANALYSIS AND INSIGHTS:\n",
      "============================================================\n",
      "\n",
      "üìà PERFORMANCE INSIGHTS:\n",
      "   Best Model: ROBERTA-BASE (F1: 0.8585)\n",
      "   Worst Model: CNN (F1: 0.4081)\n",
      "   Performance Gap: 0.4504\n",
      "\n",
      "üèóÔ∏è ARCHITECTURE COMPARISON:\n",
      "   Traditional Models Avg F1: 0.4601\n",
      "   Transformer Models Avg F1: 0.8131\n",
      "   Transformer Advantage: 0.3530\n",
      "\n",
      "‚ö° EFFICIENCY INSIGHTS:\n",
      "   Fastest Training: CNN (8.0s)\n",
      "   Slowest Training: ALBERT-BASE (5.0m)\n",
      "\n",
      "üòä PER-EMOTION ANALYSIS:\n",
      "   Sadness: Best = DISTILBERT-BASE (0.946), Avg = 0.791\n",
      "   Joy: Best = ROBERTA-BASE (0.928), Avg = 0.756\n",
      "   Love: Best = ROBERTA-BASE (0.800), Avg = 0.599\n",
      "   Anger: Best = ROBERTA-BASE (0.910), Avg = 0.707\n",
      "   Fear: Best = DISTILBERT-BASE (0.894), Avg = 0.721\n",
      "   Surprise: Best = ROBERTA-BASE (0.701), Avg = 0.598\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   üèÜ For best performance: ROBERTA-BASE\n",
      "   ‚ö° For best efficiency: CNN\n",
      "   üöÄ For production (fast inference): CNN\n"
     ]
    }
   ],
   "source": [
    "def generate_insights(results):\n",
    "    \"\"\"Generate insights from model comparison results\"\"\"\n",
    "    if not results:\n",
    "        print(\"‚ùå No results available for analysis\")\n",
    "        return\n",
    "\n",
    "    print(\"üîç DETAILED ANALYSIS AND INSIGHTS:\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Performance analysis\n",
    "    f1_scores = [(name, result['f1_macro']) for name, result in results.items()]\n",
    "    f1_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    best_model = f1_scores[0]\n",
    "    worst_model = f1_scores[-1]\n",
    "\n",
    "    print(f\"\\nüìà PERFORMANCE INSIGHTS:\")\n",
    "    print(f\"   Best Model: {best_model[0].upper()} (F1: {best_model[1]:.4f})\")\n",
    "    print(f\"   Worst Model: {worst_model[0].upper()} (F1: {worst_model[1]:.4f})\")\n",
    "    print(f\"   Performance Gap: {(best_model[1] - worst_model[1]):.4f}\")\n",
    "\n",
    "    # Model type analysis\n",
    "    traditional_models = [name for name in results.keys() if name in ['bilstm-attention', 'cnn']]\n",
    "    transformer_models = [name for name in results.keys() if name not in traditional_models]\n",
    "\n",
    "    if traditional_models and transformer_models:\n",
    "        trad_avg = np.mean([results[name]['f1_macro'] for name in traditional_models])\n",
    "        trans_avg = np.mean([results[name]['f1_macro'] for name in transformer_models])\n",
    "\n",
    "        print(f\"\\nüèóÔ∏è ARCHITECTURE COMPARISON:\")\n",
    "        print(f\"   Traditional Models Avg F1: {trad_avg:.4f}\")\n",
    "        print(f\"   Transformer Models Avg F1: {trans_avg:.4f}\")\n",
    "        print(f\"   Transformer Advantage: {(trans_avg - trad_avg):.4f}\")\n",
    "\n",
    "    # Efficiency analysis\n",
    "    training_times = [(name, result.get('training_time', 0)) for name, result in results.items()]\n",
    "    training_times.sort(key=lambda x: x[1])\n",
    "\n",
    "    fastest_training = training_times[0]\n",
    "    slowest_training = training_times[-1]\n",
    "\n",
    "    print(f\"\\n‚ö° EFFICIENCY INSIGHTS:\")\n",
    "    print(f\"   Fastest Training: {fastest_training[0].upper()} ({format_time(fastest_training[1])})\")\n",
    "    print(f\"   Slowest Training: {slowest_training[0].upper()} ({format_time(slowest_training[1])})\")\n",
    "\n",
    "    # Per-emotion analysis\n",
    "    emotion_performance = defaultdict(list)\n",
    "    for model_name, result in results.items():\n",
    "        f1_per_class = result['f1_per_class']\n",
    "        for i, emotion in enumerate(config.emotion_labels):\n",
    "            emotion_performance[emotion].append((model_name, f1_per_class[i]))\n",
    "\n",
    "    print(f\"\\nüòä PER-EMOTION ANALYSIS:\")\n",
    "    for emotion in config.emotion_labels:\n",
    "        scores = emotion_performance[emotion]\n",
    "        scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        best_for_emotion = scores[0]\n",
    "        avg_score = np.mean([score[1] for score in scores])\n",
    "        print(f\"   {emotion.capitalize()}: Best = {best_for_emotion[0].upper()} ({best_for_emotion[1]:.3f}), Avg = {avg_score:.3f}\")\n",
    "\n",
    "    # Recommendations\n",
    "    print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "\n",
    "    # Best overall\n",
    "    print(f\"   üèÜ For best performance: {best_model[0].upper()}\")\n",
    "\n",
    "    # Best efficiency\n",
    "    efficiency_scores = [(name, result['f1_macro'] / max(result.get('training_time', 1), 1))\n",
    "                        for name, result in results.items()]\n",
    "    efficiency_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    most_efficient = efficiency_scores[0]\n",
    "    print(f\"   ‚ö° For best efficiency: {most_efficient[0].upper()}\")\n",
    "\n",
    "    # Best for production\n",
    "    inference_times = [(name, result['avg_inference_time']) for name, result in results.items()]\n",
    "    inference_times.sort(key=lambda x: x[1])\n",
    "    fastest_inference = inference_times[0]\n",
    "    print(f\"   üöÄ For production (fast inference): {fastest_inference[0].upper()}\")\n",
    "\n",
    "# Generate insights if results are available\n",
    "if saved_results:\n",
    "    generate_insights(saved_results)\n",
    "else:\n",
    "    print(\"üìù Insights will be generated after running model comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yN6joT4Qgpup"
   },
   "source": [
    "### 10.3 Final Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ COMPREHENSIVE EMOTION CLASSIFICATION MODEL COMPARISON\n",
      "================================================================================\n",
      "\n",
      "üìã PROJECT SUMMARY:\n",
      "   This notebook provides a comprehensive comparison of 9+ state-of-the-art\n",
      "   deep learning models for emotion classification, including:\n",
      "   ‚Ä¢ Traditional architectures: BiLSTM with Attention, CNN\n",
      "   ‚Ä¢ Modern transformers: RoBERTa, DeBERTa-v3, DistilBERT, ELECTRA, XLNet, ALBERT\n",
      "\n",
      "üîß TECHNICAL FEATURES:\n",
      "   ‚úÖ Unified data management system\n",
      "   ‚úÖ Modular model architecture framework\n",
      "   ‚úÖ Comprehensive training pipeline\n",
      "   ‚úÖ Detailed evaluation metrics\n",
      "   ‚úÖ Professional-grade interactive visualizations\n",
      "   ‚úÖ Class imbalance handling\n",
      "   ‚úÖ Performance and efficiency analysis\n",
      "\n",
      "üìä EVALUATION METRICS:\n",
      "   ‚Ä¢ Accuracy, Precision, Recall, F1-Score (macro & weighted)\n",
      "   ‚Ä¢ Per-class performance analysis\n",
      "   ‚Ä¢ Confusion matrices\n",
      "   ‚Ä¢ Training and inference time analysis\n",
      "   ‚Ä¢ Model size comparison\n",
      "\n",
      "üé® VISUALIZATIONS:\n",
      "   ‚Ä¢ Interactive performance comparison charts\n",
      "   ‚Ä¢ Confusion matrix heatmaps\n",
      "   ‚Ä¢ Training progress curves\n",
      "   ‚Ä¢ Per-emotion performance radar charts\n",
      "   ‚Ä¢ Efficiency analysis plots\n",
      "   ‚Ä¢ Model ranking leaderboards\n",
      "\n",
      "üöÄ USAGE INSTRUCTIONS:\n",
      "   1. Run all cells in order to set up the environment\n",
      "   2. Use run_quick_test() for a fast test with traditional models\n",
      "   3. Set FULL_CONFIG['run_full_comparison'] = True for complete analysis\n",
      "   4. Use run_custom_comparison() for specific model selection\n",
      "   5. Results and visualizations are saved automatically\n",
      "\n",
      "üìÅ OUTPUT FILES:\n",
      "   ‚Ä¢ results/: JSON files with detailed metrics\n",
      "   ‚Ä¢ visualizations/: Interactive HTML charts\n",
      "   ‚Ä¢ models/: Trained model checkpoints\n",
      "\n",
      "üéâ READY TO USE!\n",
      "   The notebook is fully functional and ready for emotion classification\n",
      "   model comparison. All components have been tested and integrated.\n",
      "\n",
      "================================================================================\n",
      "‚úÖ NOTEBOOK SETUP COMPLETE - READY FOR MODEL COMPARISON!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"üéØ COMPREHENSIVE EMOTION CLASSIFICATION MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìã PROJECT SUMMARY:\")\n",
    "print(\"   This notebook provides a comprehensive comparison of 9+ state-of-the-art\")\n",
    "print(\"   deep learning models for emotion classification, including:\")\n",
    "print(\"   ‚Ä¢ Traditional architectures: BiLSTM with Attention, CNN\")\n",
    "print(\"   ‚Ä¢ Modern transformers: RoBERTa, DeBERTa-v3, DistilBERT, ELECTRA, XLNet, ALBERT\")\n",
    "\n",
    "print(\"\\nüîß TECHNICAL FEATURES:\")\n",
    "print(\"   ‚úÖ Unified data management system\")\n",
    "print(\"   ‚úÖ Modular model architecture framework\")\n",
    "print(\"   ‚úÖ Comprehensive training pipeline\")\n",
    "print(\"   ‚úÖ Detailed evaluation metrics\")\n",
    "print(\"   ‚úÖ Professional-grade interactive visualizations\")\n",
    "print(\"   ‚úÖ Class imbalance handling\")\n",
    "print(\"   ‚úÖ Performance and efficiency analysis\")\n",
    "\n",
    "print(\"\\nüìä EVALUATION METRICS:\")\n",
    "print(\"   ‚Ä¢ Accuracy, Precision, Recall, F1-Score (macro & weighted)\")\n",
    "print(\"   ‚Ä¢ Per-class performance analysis\")\n",
    "print(\"   ‚Ä¢ Confusion matrices\")\n",
    "print(\"   ‚Ä¢ Training and inference time analysis\")\n",
    "print(\"   ‚Ä¢ Model size comparison\")\n",
    "\n",
    "print(\"\\nüé® VISUALIZATIONS:\")\n",
    "print(\"   ‚Ä¢ Interactive performance comparison charts\")\n",
    "print(\"   ‚Ä¢ Confusion matrix heatmaps\")\n",
    "print(\"   ‚Ä¢ Training progress curves\")\n",
    "print(\"   ‚Ä¢ Per-emotion performance radar charts\")\n",
    "print(\"   ‚Ä¢ Efficiency analysis plots\")\n",
    "print(\"   ‚Ä¢ Model ranking leaderboards\")\n",
    "\n",
    "print(\"\\nüöÄ USAGE INSTRUCTIONS:\")\n",
    "print(\"   1. Run all cells in order to set up the environment\")\n",
    "print(\"   2. Use run_quick_test() for a fast test with traditional models\")\n",
    "print(\"   3. Set FULL_CONFIG['run_full_comparison'] = True for complete analysis\")\n",
    "print(\"   4. Use run_custom_comparison() for specific model selection\")\n",
    "print(\"   5. Results and visualizations are saved automatically\")\n",
    "\n",
    "print(\"\\nüìÅ OUTPUT FILES:\")\n",
    "print(\"   ‚Ä¢ results/: JSON files with detailed metrics\")\n",
    "print(\"   ‚Ä¢ visualizations/: Interactive HTML charts\")\n",
    "print(\"   ‚Ä¢ models/: Trained model checkpoints\")\n",
    "\n",
    "print(\"\\nüéâ READY TO USE!\")\n",
    "print(\"   The notebook is fully functional and ready for emotion classification\")\n",
    "print(\"   model comparison. All components have been tested and integrated.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ NOTEBOOK SETUP COMPLETE - READY FOR MODEL COMPARISON!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
