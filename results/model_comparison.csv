Model,Accuracy,F1-Macro,F1-Weighted,Precision,Recall,Training Time (s),Inference Time (ms),Model Size (M),Samples
albert-base,0.9345,0.8896104485685351,0.9338656215968498,0.8993810961077182,0.8810721120909445,905.4996945858002,19.28459930419922,11.688198,2000
roberta-base,0.9285,0.8872293311860043,0.9297699036477692,0.8729621626127653,0.9053861492912582,30043.77309536934,16.03975486755371,124.650246,2000
distilbert-base,0.927,0.8853981301985518,0.9267394370047652,0.8974443819092603,0.8791581399075378,456.9057722091675,9.237970352172852,66.958086,2000
electra-base,0.9305,0.8846961893866504,0.9301433936892108,0.8939293175388027,0.8797023054613645,882.9772217273712,19.718036651611328,109.486854,2000
bilstm-attention,0.891,0.8571567860867647,0.8935867387580692,0.8290754730923845,0.8989543160820346,89.38981914520264,9.030033111572266,3.156735,2000
cnn,0.8845,0.8482899123077665,0.8871262735465147,0.825286268958579,0.8843857416657287,36.8459575176239,2.4035415649414062,0.934398,2000
